{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be654757-663f-4d22-9b50-513985270c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyspark Imports\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import col, regexp_replace\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "import geopy.distance\n",
    "import time \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95536005-141b-4cee-87eb-ff20ca5c2b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/12 17:25:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/01/12 17:25:57 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "# initialize sparkSession, make the data from csv to parquet,\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"4 Executors\") \\\n",
    "    .config(\"spark.driver.cores\", \"1\") \\\n",
    "    .config(\"spark.driver.memory\", \"1g\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18270e7d-55e5-46e8-9935-d90f196ba6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# load data into memory, do the necessary joins etc. here\n",
    "crime_data = spark.read.parquet(\"hdfs://okeanos-master:54310/parquet/crime_data_*.parquet\")\n",
    "revge = spark.read.parquet(\"hdfs://okeanos-master:54310/parquet/revgecoding.parquet\")\n",
    "# only 2015 income data needed\n",
    "income = spark.read \\\n",
    "            .parquet(\"hdfs://okeanos-master:54310/parquet/income/LA_income_2015.parquet\")\n",
    "lapd_stations = spark.read.parquet(\"hdfs://okeanos-master:54310/parquet/LAPD_Police_Stations.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "956b56f6-f52f-4fd7-a1d9-1e64a5299996",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_data = crime_data.withColumn(\"Date Rptd\", to_timestamp(\"Date Rptd\", 'MM/dd/yyyy hh:mm:ss a')) \\\n",
    "    .withColumn(\"DATE OCC\", to_timestamp(\"DATE OCC\", 'MM/dd/yyyy hh:mm:ss a')) \\\n",
    "    .withColumn(\"Vict Age\", col(\"Vict Age\").cast(\"int\")) \\\n",
    "    .withColumn(\"LAT\", col(\"LAT\").cast(\"double\")) \\\n",
    "    .withColumn(\"LON\", col(\"LON\").cast(\"double\")) \\\n",
    "    .withColumn(\"Premis_Desc\", col(\"Premis Desc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c85a133-6c04-48ec-be3c-25232d33a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance on a sphere (as earth is not flat)\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    R = 6371\n",
    "    dLat = math.radians(lat2 - lat1)\n",
    "    dLon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dLat / 2) * math.sin(dLat / 2) + \\\n",
    "        math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dLon / 2) * math.sin(dLon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "haversine_udf = udf(haversine, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f635ab2c-8c42-433b-880a-ba2d24d4978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_4_2a(method = 'CONTINUE'):\n",
    "    start_time = time.time()\n",
    "\n",
    "    crime_data_filtered = crime_data.withColumn('Weapon Used Cd', col('Weapon Used Cd').cast('int')) \\\n",
    "                                    .filter(col('Weapon Used Cd') < 200) \\\n",
    "                                    .withColumn('year', F.year('Date Rptd'))\n",
    "    crime_data_filtered.count()\n",
    "\n",
    "    if method == 'BROADCAST':\n",
    "        combined_data = crime_data_filtered.hint(method).crossJoin(broadcast(lapd_stations))\n",
    "        #combined_data.explain()\n",
    "    elif method in ['MERGE', 'SHUFFLE_HASH', 'SHUFFLE_REPLICATE_NL']:\n",
    "        combined_data = crime_data_filtered.hint(method).crossJoin(lapd_stations)\n",
    "        #combined_data.explain()\n",
    "    elif method == 'CONTINUE':\n",
    "        combined_data = crime_data_filtered.crossJoin(lapd_stations)\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "    combined_data = combined_data.withColumn(\"closest_distance\", haversine_udf(col(\"LON\"), col(\"LAT\"), col(\"X\"), col(\"Y\")))\n",
    "    \n",
    "    windowSpec = Window.partitionBy(\"DR_NO\").orderBy(\"closest_distance\")\n",
    "    closest_stations = combined_data.withColumn(\"rank\", rank().over(windowSpec)).filter(col(\"rank\") == 1)\n",
    "    \n",
    "    final_data = closest_stations.select(col(\"DR_NO\"), col(\"DIVISION\").alias(\"closest_station\"), col(\"closest_distance\"))\n",
    "    \n",
    "    joined_with_stations = crime_data_filtered.join(final_data, \"DR_NO\")\n",
    "    \n",
    "    result = joined_with_stations.groupBy('year') \\\n",
    "        .agg((F.sum('closest_distance') / F.count('*')).alias('average_distance'),\n",
    "            F.count('*').alias('#')) \\\n",
    "       .orderBy(F.col('year'))\n",
    "\n",
    "    \n",
    "    result.show()\n",
    "    end_time = time.time()\n",
    "    result.explain()\n",
    "    print(f'Method : {method} | Time {end_time - start_time}')\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d22aeb5b-3669-4228-a850-03ad42753ff9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#query_4_2a('BROADCAST')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc3efe7a-3268-4171-91ce-d3ae7a07bcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+-----+\n",
      "|year|  average_distance|    #|\n",
      "+----+------------------+-----+\n",
      "|2010| 3.975757820822703| 8162|\n",
      "|2011|2.4590852830727146| 7225|\n",
      "|2012|37.105294020349675| 6539|\n",
      "|2013| 2.459919591596103| 5851|\n",
      "|2014|10.659354948051519| 4559|\n",
      "|2015|2.3889866668876247| 6729|\n",
      "|2016| 2.426807775899854| 8094|\n",
      "|2017| 4.006458967994435| 7781|\n",
      "|2018|2.4123576588935935| 7414|\n",
      "|2019| 2.431125732539258| 7135|\n",
      "|2020| 8.300434266099346| 8496|\n",
      "|2021| 32.06688876866874|17410|\n",
      "|2022|2.3181733400905906|10139|\n",
      "|2023|2.2683855904462287| 8955|\n",
      "+----+------------------+-----+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [year#286 ASC NULLS FIRST], true, 0\n",
      "   +- Exchange rangepartitioning(year#286 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=482]\n",
      "      +- HashAggregate(keys=[year#286], functions=[sum(closest_distance#389), count(1)])\n",
      "         +- Exchange hashpartitioning(year#286, 200), ENSURE_REQUIREMENTS, [plan_id=479]\n",
      "            +- HashAggregate(keys=[year#286], functions=[partial_sum(closest_distance#389), partial_count(1)])\n",
      "               +- Project [year#286, closest_distance#389]\n",
      "                  +- BroadcastHashJoin [DR_NO#0], [DR_NO#479], Inner, BuildLeft, false\n",
      "                     :- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [plan_id=474]\n",
      "                     :  +- Project [DR_NO#0, year(cast(gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) as date)) AS year#286]\n",
      "                     :     +- Filter ((isnotnull(Weapon Used Cd#16) AND (Weapon Used Cd#16 < 200)) AND isnotnull(DR_NO#0))\n",
      "                     :        +- FileScan parquet [DR_NO#0,Date Rptd#1,Weapon Used Cd#16] Batched: true, DataFilters: [isnotnull(Weapon Used Cd#16), (Weapon Used Cd#16 < 200), isnotnull(DR_NO#0)], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [IsNotNull(`Weapon Used Cd`), LessThan(`Weapon Used Cd`,200), IsNotNull(DR_NO)], ReadSchema: struct<DR_NO:int,Date Rptd:string,Weapon Used Cd:int>\n",
      "                     +- Project [DR_NO#479, closest_distance#389]\n",
      "                        +- Filter (rank#430 = 1)\n",
      "                           +- Window [rank(closest_distance#389) windowspecdefinition(DR_NO#479, closest_distance#389 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank#430], [DR_NO#479], [closest_distance#389 ASC NULLS FIRST]\n",
      "                              +- WindowGroupLimit [DR_NO#479], [closest_distance#389 ASC NULLS FIRST], rank(closest_distance#389), 1, Final\n",
      "                                 +- Sort [DR_NO#479 ASC NULLS FIRST, closest_distance#389 ASC NULLS FIRST], false, 0\n",
      "                                    +- Exchange hashpartitioning(DR_NO#479, 200), ENSURE_REQUIREMENTS, [plan_id=467]\n",
      "                                       +- WindowGroupLimit [DR_NO#479], [closest_distance#389 ASC NULLS FIRST], rank(closest_distance#389), 1, Partial\n",
      "                                          +- Sort [DR_NO#479 ASC NULLS FIRST, closest_distance#389 ASC NULLS FIRST], false, 0\n",
      "                                             +- Project [DR_NO#479, pythonUDF0#652 AS closest_distance#389]\n",
      "                                                +- BatchEvalPython [haversine(LON#506, LAT#505, X#68, Y#69)#388], [pythonUDF0#652]\n",
      "                                                   +- CartesianProduct\n",
      "                                                      :- Project [DR_NO#479, LAT#505, LON#506]\n",
      "                                                      :  +- Filter ((isnotnull(Weapon Used Cd#495) AND (Weapon Used Cd#495 < 200)) AND isnotnull(DR_NO#479))\n",
      "                                                      :     +- FileScan parquet [DR_NO#479,Weapon Used Cd#495,LAT#505,LON#506] Batched: true, DataFilters: [isnotnull(Weapon Used Cd#495), (Weapon Used Cd#495 < 200), isnotnull(DR_NO#479)], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [IsNotNull(`Weapon Used Cd`), LessThan(`Weapon Used Cd`,200), IsNotNull(DR_NO)], ReadSchema: struct<DR_NO:int,Weapon Used Cd:int,LAT:double,LON:double>\n",
      "                                                      +- FileScan parquet [X#68,Y#69] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/LAPD_Police_Stations.parquet], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<X:double,Y:double>\n",
      "\n",
      "\n",
      "Method : SHUFFLE_REPLICATE_NL | Time 19.95678186416626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19.95678186416626"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_4_2a('SHUFFLE_REPLICATE_NL')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a5f93f8-91e7-45b6-b62b-8053fc1495cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54474803-31a2-499f-adcc-0e5c34f5f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b)\n",
    "def query_4_2b(method = 'CONTINUE'):\n",
    "    start_time = time.time()\n",
    "\n",
    "    crime_data_filtered = crime_data.withColumn('Weapon Used Cd', col('Weapon Used Cd').cast('int')) \\\n",
    "                                  .filter(F.col('Weapon Used Cd').isNotNull()) \\\n",
    "                                  .withColumn('year', F.year('Date Rptd'))\n",
    "    \n",
    "    if method == 'BROADCAST':\n",
    "        combined_data = crime_data_filtered.hint(method).crossJoin(broadcast(lapd_stations))\n",
    "    elif method in ['MERGE', 'SHUFFLE_HASH', 'SHUFFLE_REPLICATE_NL']:\n",
    "        combined_data = crime_data_filtered.hint(method).crossJoin(lapd_stations)    \n",
    "    elif method == 'CONTINUE':\n",
    "        combined_data = crime_data_filtered.crossJoin(lapd_stations)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    \n",
    "    combined_data = combined_data.withColumn(\"closest_distance\", haversine_udf(col(\"LON\"), col(\"LAT\"), col(\"X\"), col(\"Y\")))\n",
    "    \n",
    "    windowSpec = Window.partitionBy(\"DR_NO\").orderBy(\"closest_distance\")\n",
    "    closest_stations = combined_data.withColumn(\"rank\", rank().over(windowSpec)).filter(col(\"rank\") == 1)\n",
    "    \n",
    "    final_data = closest_stations.select(col(\"DR_NO\"), col(\"DIVISION\").alias(\"closest_station\"), col(\"closest_distance\"))\n",
    "    \n",
    "    joined_result = crime_data_filtered.join(final_data, \"DR_NO\")\n",
    "   # crime_data_join_stations = result.withColumn('Weapon Used Cd', col('Weapon Used Cd').cast('int')) \\\n",
    "   #                               .filter(F.col('Weapon Used Cd').isNotNull()) \\\n",
    "   #                                 .withColumn('year', F.year('Date Rptd'))\n",
    "    \n",
    "    result = joined_result.groupBy('AREA NAME') \\\n",
    "        .agg(\n",
    "            (F.sum('closest_distance') / F.count('*')).alias('average_distance'),\n",
    "            F.count('*').alias('#')\n",
    "        ) \\\n",
    "        .orderBy(F.col('#').desc()) \\\n",
    "        .withColumnRenamed('AREA NAME', 'division')\n",
    "    \n",
    "    result.show()\n",
    "    end_time = time.time()\n",
    "    result.explain()\n",
    "    print(f'Method : {method} | Time {end_time - start_time}')\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfcf89c7-1eac-460f-8e5e-505c71c40684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_4_2b(\"BROADCAST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ed59a9e-1376-4016-b4ad-f21fa1e0ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9e4660f-a518-41ad-86b7-ea28e2046fb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-----+\n",
      "|   division|  average_distance|    #|\n",
      "+-----------+------------------+-----+\n",
      "|77th Street|  12.5671222967951|94853|\n",
      "|  Southeast|25.601298738797514|87905|\n",
      "|  Southwest|   9.3291866625766|72814|\n",
      "|    Central|23.269811961478677|63606|\n",
      "|     Newton| 13.43318472129279|61408|\n",
      "|    Olympic|36.348197450528986|60925|\n",
      "|    Rampart|19.629568008429306|55881|\n",
      "|  Hollywood|27.671748021149362|51255|\n",
      "|    Mission|34.800525588613944|48956|\n",
      "|    Pacific|24.825461959674012|43019|\n",
      "|   Foothill|29.797575113580425|41625|\n",
      "| Hollenbeck| 19.52127635437576|41540|\n",
      "|N Hollywood|17.691483131562673|41151|\n",
      "|     Harbor|13.982027989409769|40854|\n",
      "|    Topanga| 6.096105827278326|39337|\n",
      "|   Wilshire|15.736618712905988|37930|\n",
      "|  Northeast|12.367411075059351|37334|\n",
      "| Devonshire|23.046036251700613|36902|\n",
      "|   Van Nuys| 19.78805706517812|36264|\n",
      "|West Valley|14.718040243069364|34005|\n",
      "+-----------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [AREA NAME#5 AS division#548, average_distance#542, ##544L]\n",
      "   +- Sort [##544L DESC NULLS LAST], true, 0\n",
      "      +- Exchange rangepartitioning(##544L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=472]\n",
      "         +- HashAggregate(keys=[AREA NAME#5], functions=[sum(closest_distance#354), count(1)])\n",
      "            +- Exchange hashpartitioning(AREA NAME#5, 200), ENSURE_REQUIREMENTS, [plan_id=469]\n",
      "               +- HashAggregate(keys=[AREA NAME#5], functions=[partial_sum(closest_distance#354), partial_count(1)])\n",
      "                  +- Project [AREA NAME#5, closest_distance#354]\n",
      "                     +- SortMergeJoin [DR_NO#0], [DR_NO#444], Inner\n",
      "                        :- Sort [DR_NO#0 ASC NULLS FIRST], false, 0\n",
      "                        :  +- Exchange hashpartitioning(DR_NO#0, 200), ENSURE_REQUIREMENTS, [plan_id=463]\n",
      "                        :     +- Project [DR_NO#0, AREA NAME#5]\n",
      "                        :        +- Filter (isnotnull(Weapon Used Cd#16) AND isnotnull(DR_NO#0))\n",
      "                        :           +- FileScan parquet [DR_NO#0,AREA NAME#5,Weapon Used Cd#16] Batched: true, DataFilters: [isnotnull(Weapon Used Cd#16), isnotnull(DR_NO#0)], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [IsNotNull(`Weapon Used Cd`), IsNotNull(DR_NO)], ReadSchema: struct<DR_NO:int,AREA NAME:string,Weapon Used Cd:int>\n",
      "                        +- Project [DR_NO#444, closest_distance#354]\n",
      "                           +- Filter (rank#395 = 1)\n",
      "                              +- Window [rank(closest_distance#354) windowspecdefinition(DR_NO#444, closest_distance#354 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank#395], [DR_NO#444], [closest_distance#354 ASC NULLS FIRST]\n",
      "                                 +- WindowGroupLimit [DR_NO#444], [closest_distance#354 ASC NULLS FIRST], rank(closest_distance#354), 1, Final\n",
      "                                    +- Sort [DR_NO#444 ASC NULLS FIRST, closest_distance#354 ASC NULLS FIRST], false, 0\n",
      "                                       +- Exchange hashpartitioning(DR_NO#444, 200), ENSURE_REQUIREMENTS, [plan_id=455]\n",
      "                                          +- WindowGroupLimit [DR_NO#444], [closest_distance#354 ASC NULLS FIRST], rank(closest_distance#354), 1, Partial\n",
      "                                             +- Sort [DR_NO#444 ASC NULLS FIRST, closest_distance#354 ASC NULLS FIRST], false, 0\n",
      "                                                +- Project [DR_NO#444, pythonUDF0#621 AS closest_distance#354]\n",
      "                                                   +- BatchEvalPython [haversine(LON#471, LAT#470, X#68, Y#69)#353], [pythonUDF0#621]\n",
      "                                                      +- CartesianProduct\n",
      "                                                         :- Project [DR_NO#444, LAT#470, LON#471]\n",
      "                                                         :  +- Filter (isnotnull(Weapon Used Cd#460) AND isnotnull(DR_NO#444))\n",
      "                                                         :     +- FileScan parquet [DR_NO#444,Weapon Used Cd#460,LAT#470,LON#471] Batched: true, DataFilters: [isnotnull(Weapon Used Cd#460), isnotnull(DR_NO#444)], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [IsNotNull(`Weapon Used Cd`), IsNotNull(DR_NO)], ReadSchema: struct<DR_NO:int,Weapon Used Cd:int,LAT:double,LON:double>\n",
      "                                                         +- FileScan parquet [X#68,Y#69] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/LAPD_Police_Stations.parquet], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<X:double,Y:double>\n",
      "\n",
      "\n",
      "Method : SHUFFLE_REPLICATE_NL | Time 47.28730773925781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47.28730773925781"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query_4_2b(\"SHUFFLE_REPLICATE_NL\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
