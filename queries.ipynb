{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56c50ab-5769-4e7d-946c-ec870888801c",
   "metadata": {},
   "source": [
    "#### Useful Links \n",
    "- Spark History Server : http://83.212.73.248:18080/\n",
    "- Hadoop YARN (scheduler) : http://83.212.73.248:8088/cluster\n",
    "- HDFS : http://83.212.73.248:9870/dfshealth.html#tab-overview\n",
    "\n",
    "#### Useful Commands : \n",
    "- Connect to okeanos-master (from local) : `$ ssh user@snf-40202.ok-kno.grnetcloud.net `\n",
    "    - Password : 'Rand0m'\n",
    "- Connect to okeanos-worker (from okeanos-master) : `$ ssh okeanos-worker`\n",
    "- Open Jupyter Notebook : `$ jupyter notebook --ip 83.212.73.248 --port 8888`\n",
    "\n",
    "#### Thinks to do :\n",
    "- Make the data Csv to Parquet\n",
    "- Make those columns the type we want\n",
    "- Write the Queries (!)\n",
    "- Benchmark and optimize them etc.\n",
    "- Balance the data onto HDFS across the two datanodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c667a612-a781-4680-bb05-0fdfe7aed047",
   "metadata": {},
   "source": [
    "### Full HDFS path is here : hdfs://okeanos-master:54310/csv_data/\n",
    "and contains :  \n",
    "     \n",
    "     1.  hdfs://okeanos-master:54310/csv_data/LAPD_Police_Stations.csv\n",
    "     2.  hdfs://okeanos-master:54310/csv_data/crime_data_2019.csv \n",
    "     3.  hdfs://okeanos-master:54310/csv_data/crime_data_2023.csv\n",
    "     4.  hdfs://okeanos-master:54310/csv_data/revgecoding.csv \n",
    "     5.  hdfs://okeanos-master:54310/csv_data/income/\n",
    "         1. LA_income_2015.csv\n",
    "         2. LA_income_2017.csv\n",
    "         3. LA_income_2019.csv\n",
    "         4. LA_income_2021.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a4e254-eda8-4782-a680-a9fc5c1d69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyspark Imports\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbb858d-c65c-40f6-93c8-eae9504bbf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/25 19:07:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/12/25 19:07:31 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "# initialize sparkSession, make the data from csv to parquet,\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"First Query\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaaacbe-53a0-4f5d-bf6f-f6eb6c42e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into memory, do the necessary joins etc. here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ad4d5-4e37-41a5-8833-7b3969368d31",
   "metadata": {},
   "source": [
    "#### Change Column Types \n",
    "Στην εκφωνηση λέει : Διατηρώντας τα αρχικά ονόματα στηλών \n",
    "\n",
    "εννοωντας οτι δεν μπορουμε να κανουμε το 'Date Rptd' -> 'Date_Rptd' ?\n",
    "- Date Rptd: date\n",
    "- DATE OCC: date\n",
    "- Vict Age: integer\n",
    "- LAT: double\n",
    "- LON: double\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b85974b-2551-4dda-859a-e86e3011dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for column type changing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7729edb-fff8-4a31-b7bd-4dd61a4ea834",
   "metadata": {},
   "source": [
    "# 1st Query :\r\n",
    "        find\r\n",
    "            for each year\r\n",
    "                the 3 months with the biggest crime count\r\n",
    "\r\n",
    "        year | month | crime_total (count)  + #order\r\n",
    "        dataframe.show()\r\n",
    "\r\n",
    "        SELECT  YEAR(date_rptd) as year,\r\n",
    "                MONTH(date_rptd) as month,\r\n",
    "                COUNT(*) as crime_total,\r\n",
    "                ROW_NUMBER() OVER (PARTITION BY year ORDER BY crime_total) as '#'\r\n",
    "        GROUP BY YEAR(date_rptd), MONTH(date_rptd)\r\n",
    "        SORT BY year ASC, crime_total DESp    GROUP BY police_station_name\r\n",
    "                ORDER BY #\r\n",
    "\r\n",
    "    2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db03eee5-f317-4051-b526-4092b7522187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for first query in SQL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39898c69-f992-45c8-a534-8ee164828c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for first query in Dataframe API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55eda9-3400-4cf9-a5a8-2247792fd456",
   "metadata": {},
   "source": [
    " # 2nd Query :\n",
    "\n",
    "\n",
    "            SELECT street,\n",
    "                   CASE\n",
    "                      WHEN HOUR(date_rptd) BETWEEN 5 AND 11 THEN 'Morning'\n",
    "                      WHEN HOUR(date_rptd) BETWEEN 12 AND 16 THEN 'Noon'\n",
    "                      WHEN HOUR(date_rptd) BETWEEN 17 AND 20 THEN 'Afternoon'\n",
    "                      ELSE 'Night'\n",
    "                    END AS time_group,\n",
    "                    COUNT(*) as count\n",
    "            WHERE prem_desc='STREET'\n",
    "            GROUP BY time_group\n",
    "            ORDER BY count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6c1df-26e6-4b93-b9ee-a2d5cff7a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code for 2nd query here for Dataframe/SQL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a5ce5-2f86-4195-a778-a04d62f18e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code for 2nd query here for RDD API :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c962e-49f3-4409-aa0e-3b113c973570",
   "metadata": {},
   "source": [
    "# 3rd Query :\n",
    "\n",
    "        find the 3 zip codes with min and max household income\n",
    "                    |\n",
    "                    |\n",
    "                    v\n",
    "        // filter(remove) victimless crimes\n",
    "                    |\n",
    "                    |\n",
    "                    v\n",
    "        select vict_desc, COUNT(*) as count\n",
    "        where year=2015\n",
    "        group by vict_desc\n",
    "        order by count DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c006e0c2-4c2d-4541-ac68-10bad330ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code for 3rd query here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48047e1-8739-48ef-86b3-1cc547d2beb1",
   "metadata": {},
   "source": [
    "# 4th Query :\n",
    "    1 :\n",
    "        a)\n",
    "                make_extra_columns() : distance of police stations from crime\n",
    "                join crime_table with LA Police Stations on police_station\n",
    "                and add column of police station\n",
    "                for each row compute distance from two coordinates                         put this computed distance in the column named 'distance'\n",
    "\n",
    "                SELECT year, SUM(distance)/# as average_distance\n",
    "                                , COUNT(*) as #\n",
    "                FROM ...\n",
    "                WHERE WEAPON='FIREARM'\n",
    "                GROUP BY year\n",
    "                ORDER BY #\n",
    "\n",
    "\n",
    "        b)\n",
    "                SELECT police_station_name as division,\n",
    "                       SUM(distance)/# as average_distance,\n",
    "                       COUNT(*) as #\n",
    "                FROM ...\n",
    "                WHERE weapon NOT NULL\n",
    "                GROUP BY police_station_name\n",
    "                ORDER BY #\n",
    "\n",
    "    2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a08e7-d25b-4e9c-af0c-c33b7c15f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code for 4th query here "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
