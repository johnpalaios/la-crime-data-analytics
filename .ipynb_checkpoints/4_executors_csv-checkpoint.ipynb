{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56c50ab-5769-4e7d-946c-ec870888801c",
   "metadata": {},
   "source": [
    "#### Useful Links \n",
    "- Spark History Server : http://83.212.73.248:18080/\n",
    "- Hadoop YARN (scheduler) : http://83.212.73.248:8088/cluster\n",
    "- HDFS : http://83.212.73.248:9870/dfshealth.html#tab-overview\n",
    "\n",
    "#### Useful Commands : \n",
    "- Connect to okeanos-master (from local) : `$ ssh user@snf-40202.ok-kno.grnetcloud.net `\n",
    "    - Password : 'Rand0m'\n",
    "- Connect to okeanos-worker (from okeanos-master) : `$ ssh okeanos-worker`\n",
    "- Open Jupyter Notebook : `$ jupyter notebook --ip 83.212.73.248 --port 8888`\n",
    "\n",
    "#### Thinks to do :\n",
    "- Make the data Csv to Parquet\n",
    "- Make those columns the type we want\n",
    "- Write the Queries (!)\n",
    "- Benchmark and optimize them etc.\n",
    "- Balance the data onto HDFS across the two datanodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c667a612-a781-4680-bb05-0fdfe7aed047",
   "metadata": {},
   "source": [
    "### Full HDFS path is here : hdfs://okeanos-master:54310/csv_data/\n",
    "and contains :  \n",
    "     \n",
    "     1.  hdfs://okeanos-master:54310/csv_data/LAPD_Police_Stations.csv\n",
    "     2.  hdfs://okeanos-master:54310/csv_data/crime_data_2019.csv \n",
    "     3.  hdfs://okeanos-master:54310/csv_data/crime_data_2023.csv\n",
    "     4.  hdfs://okeanos-master:54310/csv_data/revgecoding.csv \n",
    "     5.  hdfs://okeanos-master:54310/csv_data/income/\n",
    "         1. LA_income_2015.csv\n",
    "         2. LA_income_2017.csv\n",
    "         3. LA_income_2019.csv\n",
    "         4. LA_income_2021.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a4e254-eda8-4782-a680-a9fc5c1d69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyspark Imports\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import col, regexp_replace\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from operator import add\n",
    "import geopy.distance\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, rank\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.window import Window\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbb858d-c65c-40f6-93c8-eae9504bbf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/04 21:33:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/01/04 21:33:10 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "# initialize sparkSession, make the data from csv to parquet,\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"4 Executors\") \\\n",
    "    .config(\"spark.driver.memory\", \"1g\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efaaacbe-53a0-4f5d-bf6f-f6eb6c42e3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# load data into memory, do the necessary joins etc. here\n",
    "df = spark.read.options(inferSchema=\"true\", delimiter=\",\", header=\"true\") \\\n",
    "    .csv(\"hdfs://okeanos-master:54310/csv_data/crime_data_2019.csv\")\n",
    "df2 = spark.read.options(inferSchema=\"true\", delimiter=\",\", header=\"true\") \\\n",
    "    .csv(\"hdfs://okeanos-master:54310/csv_data/crime_data_2023.csv\")\n",
    "crime_data = df.union(df2)\n",
    "revge = spark.read.options(inferSchema=\"true\", delimiter=\",\", header=\"true\") \\\n",
    "    .csv(\"hdfs://okeanos-master:54310/csv_data/revgecoding.csv\")\n",
    "# only 2015 income data needed\n",
    "income = spark.read \\\n",
    "            .parquet(\"hdfs://okeanos-master:54310/parquet/income/LA_income_2015.parquet\")\n",
    "lapd_stations = spark.read.parquet(\"hdfs://okeanos-master:54310/parquet/LAPD_Police_Stations.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b586a4fc-878b-4370-91e1-36faca721379",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0098ff2-3857-4604-8d16-5c26d003759e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      " |-- _c20: string (nullable = true)\n",
      " |-- _c21: string (nullable = true)\n",
      " |-- _c22: string (nullable = true)\n",
      " |-- _c23: string (nullable = true)\n",
      " |-- _c24: string (nullable = true)\n",
      " |-- _c25: string (nullable = true)\n",
      " |-- _c26: string (nullable = true)\n",
      " |-- _c27: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crime_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ad4d5-4e37-41a5-8833-7b3969368d31",
   "metadata": {},
   "source": [
    "#### Change Column Types \n",
    "Στην εκφωνηση λέει : Διατηρώντας τα αρχικά ονόματα στηλών \n",
    "\n",
    "εννοωντας οτι δεν μπορουμε να κανουμε το 'Date Rptd' -> 'Date_Rptd' ?\n",
    "- Date Rptd: date\n",
    "- DATE OCC: date\n",
    "- Vict Age: integer\n",
    "- LAT: double\n",
    "- LON: double\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b85974b-2551-4dda-859a-e86e3011dcea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `Date Rptd` cannot be resolved. Did you mean one of the following? [`_c0`, `_c1`, `_c10`, `_c11`, `_c12`].;\n'Project [_c0#17, _c1#18, _c2#19, _c3#20, _c4#21, _c5#22, _c6#23, _c7#24, _c8#25, _c9#26, _c10#27, _c11#28, _c12#29, _c13#30, _c14#31, _c15#32, _c16#33, _c17#34, _c18#35, _c19#36, _c20#37, _c21#38, _c22#39, _c23#40, ... 5 more fields]\n+- Relation [_c0#17,_c1#18,_c2#19,_c3#20,_c4#21,_c5#22,_c6#23,_c7#24,_c8#25,_c9#26,_c10#27,_c11#28,_c12#29,_c13#30,_c14#31,_c15#32,_c16#33,_c17#34,_c18#35,_c19#36,_c20#37,_c21#38,_c22#39,_c23#40,... 4 more fields] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# code for column type changing\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m crime_data \u001b[38;5;241m=\u001b[39m \u001b[43mcrime_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate Rptd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_timestamp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate Rptd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMM/dd/yyyy hh:mm:ss a\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATE OCC\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_timestamp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATE OCC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMM/dd/yyyy hh:mm:ss a\u001b[39m\u001b[38;5;124m'\u001b[39m)) \\\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVict Age\u001b[39m\u001b[38;5;124m\"\u001b[39m, col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVict Age\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \\\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAT\u001b[39m\u001b[38;5;124m\"\u001b[39m, col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdouble\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \\\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLON\u001b[39m\u001b[38;5;124m\"\u001b[39m, col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLON\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdouble\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \\\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPremis_Desc\u001b[39m\u001b[38;5;124m\"\u001b[39m, col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPremis Desc\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/opt/spark/python/pyspark/sql/dataframe.py:5170\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   5165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[1;32m   5166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   5167\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5168\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m   5169\u001b[0m     )\n\u001b[0;32m-> 5170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/opt/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `Date Rptd` cannot be resolved. Did you mean one of the following? [`_c0`, `_c1`, `_c10`, `_c11`, `_c12`].;\n'Project [_c0#17, _c1#18, _c2#19, _c3#20, _c4#21, _c5#22, _c6#23, _c7#24, _c8#25, _c9#26, _c10#27, _c11#28, _c12#29, _c13#30, _c14#31, _c15#32, _c16#33, _c17#34, _c18#35, _c19#36, _c20#37, _c21#38, _c22#39, _c23#40, ... 5 more fields]\n+- Relation [_c0#17,_c1#18,_c2#19,_c3#20,_c4#21,_c5#22,_c6#23,_c7#24,_c8#25,_c9#26,_c10#27,_c11#28,_c12#29,_c13#30,_c14#31,_c15#32,_c16#33,_c17#34,_c18#35,_c19#36,_c20#37,_c21#38,_c22#39,_c23#40,... 4 more fields] csv\n"
     ]
    }
   ],
   "source": [
    "# code for column type changing\n",
    "crime_data = crime_data.withColumn(\"Date Rptd\", to_timestamp(\"Date Rptd\", 'MM/dd/yyyy hh:mm:ss a')) \\\n",
    "    .withColumn(\"DATE OCC\", to_timestamp(\"DATE OCC\", 'MM/dd/yyyy hh:mm:ss a')) \\\n",
    "    .withColumn(\"Vict Age\", col(\"Vict Age\").cast(\"int\")) \\\n",
    "    .withColumn(\"LAT\", col(\"LAT\").cast(\"double\")) \\\n",
    "    .withColumn(\"LON\", col(\"LON\").cast(\"double\")) \\\n",
    "    .withColumn(\"Premis_Desc\", col(\"Premis Desc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7729edb-fff8-4a31-b7bd-4dd61a4ea834",
   "metadata": {},
   "source": [
    "# 1st Query :\r\n",
    "        find\r\n",
    "            for each year\r\n",
    "                the 3 months with the biggest crime count\r\n",
    "\r\n",
    "        year | month | crime_total (count)  + #order\r\n",
    "        dataframe.show()\r\n",
    "\r\n",
    "        SELECT  YEAR(date_rptd) as year,\r\n",
    "                MONTH(date_rptd) as month,\r\n",
    "                COUNT(*) as crime_total,\r\n",
    "                ROW_NUMBER() OVER (PARTITION BY year ORDER BY crime_total) as '#'\r\n",
    "        GROUP BY YEAR(date_rptd), MONTH(date_rptd)\r\n",
    "        SORT BY year ASC, crime_total DESp    GROUP BY police_station_name\r\n",
    "                ORDER BY #\r\n",
    "\r\n",
    "    2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db03eee5-f317-4051-b526-4092b7522187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for first query in SQL API\n",
    "def query_1_SQL_API():\n",
    "    start_time = time.time()\n",
    "    crime_data.createOrReplaceTempView(\"crime_data\")\n",
    "    \n",
    "    query = \"\"\"\n",
    "        SELECT * FROM (\n",
    "            SELECT \n",
    "                year(`Date Rptd`) AS year,\n",
    "                month(`Date Rptd`) AS month,\n",
    "                COUNT(*) AS crime_total,\n",
    "                ROW_NUMBER() OVER (PARTITION BY year(`Date Rptd`) ORDER BY COUNT(*) DESC) AS rank\n",
    "            FROM \n",
    "                crime_data\n",
    "            GROUP BY \n",
    "                year(`Date Rptd`), month(`Date Rptd`)\n",
    "        ) ranked_data\n",
    "        WHERE rank <= 3\n",
    "        ORDER BY year, rank\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    result_df = spark.sql(query)\n",
    "    result_df.show()\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39898c69-f992-45c8-a534-8ee164828c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for first query in Dataframe API\n",
    "def query_1_Dataframe_API():\n",
    "    start_time = time.time()\n",
    "    crime_counts = crime_data.withColumn(\"year\", F.year(\"Date Rptd\")) \\\n",
    "                          .withColumn(\"month\", F.month(\"Date Rptd\")) \\\n",
    "                          .groupBy(\"year\", \"month\") \\\n",
    "                          .agg(F.count(\"*\").alias(\"crime_total\"))\n",
    "    \n",
    "    window_spec = Window.partitionBy(\"year\").orderBy(F.desc(\"crime_total\"))\n",
    "    \n",
    "    ranked_crime = crime_counts.withColumn(\"rank\", F.row_number().over(window_spec))\n",
    "    \n",
    "    result_df = ranked_crime.filter(\"rank <= 3\").orderBy(\"year\", \"rank\")\n",
    "    \n",
    "    result_df.show()\n",
    "    end_time = time.time()\n",
    "\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55eda9-3400-4cf9-a5a8-2247792fd456",
   "metadata": {},
   "source": [
    " # 2nd Query :\n",
    "\n",
    "\n",
    "            SELECT street,\n",
    "                   CASE\n",
    "                      WHEN HOUR('Date Rptd') BETWEEN 5 AND 11 THEN 'Morning'\n",
    "                      WHEN HOUR('Date Rptd') BETWEEN 12 AND 16 THEN 'Noon'\n",
    "                      WHEN HOUR('Date Rptd') BETWEEN 17 AND 20 THEN 'Afternoon'\n",
    "                      ELSE 'Night'\n",
    "                    END AS time_group,\n",
    "                    COUNT(*) as count\n",
    "            WHERE 'Prem Desc'='STREET'\n",
    "            GROUP BY time_group\n",
    "            ORDER BY count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6c1df-26e6-4b93-b9ee-a2d5cff7a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code for 2nd query here for Dataframe/SQL API\n",
    "def query_2_Dataframe_API():\n",
    "    start_time = time.time()\n",
    "    filtered_df = crime_data.filter(crime_data['Premis_Desc'] == 'STREET')\n",
    "\n",
    "    time_group_df = filtered_df.withColumn(\"time_group\",\n",
    "                                       # TIME OCC is in 24 hour military time integer values\n",
    "                                      F.when((F.col('TIME OCC').between(500, 1159)), 'Morning')\n",
    "                                      .when((F.col('TIME OCC').between(1200, 1659)), 'Noon')\n",
    "                                      .when((F.col('TIME OCC').between(1700, 2059)), 'Afternoon')\n",
    "                                      .otherwise('Night'))\n",
    "\n",
    "    result_df = time_group_df.groupBy(\"time_group\").agg(F.count(\"*\").alias(\"count\"))\n",
    "\n",
    "    result_df = result_df.orderBy(col(\"count\").desc())\n",
    "    result_df.show()\n",
    "    end_time = time.time()\n",
    "    # call explain() method in order\n",
    "    # to see the query's physical plan\n",
    "    # and improve the RDD query\n",
    "    result_df.explain()\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339e48bb-fb2f-4a6a-acca-c11c76786357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code for 2nd query here for RDD API\n",
    "def time_segs(row):\n",
    "    if 500 <= int(row['TIME OCC']) <= 1159:\n",
    "        return 'Morning'\n",
    "    elif 1200 <= int(row['TIME OCC']) <= 1659:\n",
    "        return 'Noon'\n",
    "    elif 1700 <= int(row['TIME OCC']) <= 2059:\n",
    "        return 'Afternoon'\n",
    "    else:\n",
    "        return 'Night'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928f8cf-9407-4a3c-b0cc-836e78e49b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_2_rdd(): \n",
    "    #then broadcast\n",
    "    #spark.sparkContext.broadcast(crime_data)\n",
    "    # changes performance? (37s)\n",
    "\n",
    "    start_time = time.time()\n",
    "    crime_data_rdd = crime_data.rdd.filter(lambda x: x['Premis_Desc'] == 'STREET') \\\n",
    "                                .map(lambda x: (time_segs(x),1)) \\\n",
    "                                .reduceByKey(lambda k1,k2: k1+k2) \\\n",
    "                                .sortBy(lambda x: x[1], ascending = False)\n",
    "    \n",
    "    result = crime_data_rdd.collect()\n",
    "    for time_of_day, count in result:\n",
    "        print(f\"{time_of_day}: {count}\")\n",
    "        \n",
    "    end_time = time.time()\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c51ced-8b88-4c16-ad21-0b1479e9b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_time_group(row):\n",
    "    time_occ = int(row)\n",
    "    if 500 <= time_occ <= 1159:\n",
    "        return 'Morning'\n",
    "    elif 1200 <= time_occ <= 1659:\n",
    "        return 'Noon'\n",
    "    elif 1700 <= time_occ <= 2059:\n",
    "        return 'Afternoon'\n",
    "    else:\n",
    "        return 'Night'\n",
    "        \n",
    "def query_2_rdd_new():\n",
    "    start_time = time.time()\n",
    "\n",
    "    crime_data_rdd = crime_data.rdd.filter(lambda x: x['Premis_Desc'] == 'STREET') \\\n",
    "                                .map(lambda x: (map_time_group(x['TIME OCC']), 1)) \\\n",
    "                                .reduceByKey(add).sortBy(lambda x: x[1], ascending = False)\n",
    "\n",
    "    result = crime_data_rdd.collect()\n",
    "    for time_of_day, count in result:\n",
    "        print(f\"{time_of_day}: {count}\")\n",
    "        \n",
    "    end_time = time.time()\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456977f-3b8d-4620-ac19-771aafc23206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_2_Dataframe_API()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b45bf-c7a1-4f7d-8a85-e8b7827380fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2_rdd_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4ad40f-c002-49d6-bc68-230131410474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c962e-49f3-4409-aa0e-3b113c973570",
   "metadata": {},
   "source": [
    "# 3rd Query :\n",
    "\n",
    "        find the 3 zip codes with min and max household income\n",
    "                    |\n",
    "                    |\n",
    "                    v\n",
    "        // filter(remove) victimless crimes\n",
    "                    |\n",
    "                    |\n",
    "                    v\n",
    "        select vict_desc, COUNT(*) as count\n",
    "        where year=2015\n",
    "        group by vict_desc\n",
    "        order by count DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c006e0c2-4c2d-4541-ac68-10bad330ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code for 3rd query here\n",
    "def query_3(method = 'CONTINUE'):\n",
    "    start_time = time.time()\n",
    "\n",
    "    if method == 'BROADCAST':\n",
    "        crime_data_join_revge = crime_data.join(broadcast(revge), ['LAT', 'LON'], 'inner') \\\n",
    "            .withColumnRenamed('ZIPcode', 'Zip Code') \\\n",
    "            .withColumn(\"Zip Code\", col(\"Zip Code\").cast(\"int\")) \\\n",
    "            .filter((col('Vict Descent') != 'X') & (col('Vict Sex') != 'X'))\n",
    "        crime_data_join_revge.explain()\n",
    "        \n",
    "    elif method in ['MERGE', 'SHUFFLE_HASH', 'SHUFFLE_REPLICATE_NL']:\n",
    "        crime_data_join_revge = crime_data.hint(method).join(revge, ['LAT', 'LON'], 'inner') \\\n",
    "            .withColumnRenamed('ZIPcode', 'Zip Code') \\\n",
    "            .withColumn(\"Zip Code\", col(\"Zip Code\").cast(\"int\")) \\\n",
    "            .filter((col('Vict Descent') != 'X') & (col('Vict Sex') != 'X'))\n",
    "        crime_data_join_revge.explain()\n",
    "        \n",
    "    elif method == 'CONTINUE':\n",
    "        crime_data_join_revge = crime_data.join(revge, ['LAT', 'LON'], 'inner') \\\n",
    "            .withColumnRenamed('ZIPcode', 'Zip Code') \\\n",
    "            .withColumn(\"Zip Code\", col(\"Zip Code\").cast(\"int\")) \\\n",
    "            .filter((col('Vict Descent') != 'X') & (col('Vict Sex') != 'X'))\n",
    "        \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    #crime_data_join_revge = crime_data.join(revge, ['LAT', 'LON'], 'inner') \\\n",
    "    #    .withColumnRenamed('ZIPcode', 'Zip Code') \\\n",
    "    #    .withColumn(\"Zip Code\", col(\"Zip Code\").cast(\"int\")) \\\n",
    "    #    .filter((col('Vict Descent') != 'X') & (col('Vict Sex') != 'X'))\n",
    "    \n",
    "    crime_data_join_income = crime_data_join_revge.join(income, 'Zip Code', 'inner') \\\n",
    "                                .withColumn('Estimated Median Income', \n",
    "                                            regexp_replace(col('Estimated Median Income'), '[$,]', '')) \\\n",
    "                                .withColumn('Estimated Median Income', \n",
    "                                            col('Estimated Median Income') \\\n",
    "                                .cast('double'))\n",
    "    \n",
    "    max_income_zip_codes = crime_data_join_income.groupBy('Zip Code') \\\n",
    "                            .agg({'Estimated Median Income': 'max'}) \\\n",
    "                            .withColumnRenamed('max(Estimated Median Income)', 'MaxIncome') \\\n",
    "                            .orderBy(col('MaxIncome').desc()) \\\n",
    "                            .limit(3)\n",
    "    \n",
    "    min_income_zip_codes = crime_data_join_income.groupBy('Zip Code') \\\n",
    "                            .agg({'Estimated Median Income': 'min'}) \\\n",
    "                            .withColumnRenamed('min(Estimated Median Income)', 'MinIncome') \\\n",
    "                            .orderBy(col('MinIncome')) \\\n",
    "                            .limit(3)\n",
    "    \n",
    "    zip_codes = min_income_zip_codes.union(max_income_zip_codes)\n",
    "    \n",
    "    zip_codes_list = [row['Zip Code'] for row in zip_codes.collect()]\n",
    "    \n",
    "    result = crime_data_join_income \\\n",
    "                .filter(col('Zip Code').isin(zip_codes_list)) \\\n",
    "                .filter(year(col('Date Rptd')) == 2015) \\\n",
    "                .groupBy('Vict Descent') \\\n",
    "                .count() \\\n",
    "                .withColumnRenamed('count', '#') \\\n",
    "                .orderBy(col('#').desc())\n",
    "    \n",
    "    result.show()\n",
    "    end_time = time.time()\n",
    "    print(f'Method : {method} | Time {end_time - start_time}')\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48047e1-8739-48ef-86b3-1cc547d2beb1",
   "metadata": {},
   "source": [
    "# 4th Query :\n",
    "    1 :\n",
    "        a)\n",
    "                make_extra_columns() : distance of police stations from crime\n",
    "                join crime_table with LA Police Stations on police_station\n",
    "                and add column of police station\n",
    "                for each row compute distance from two coordinates                         \n",
    "                put this computed distance in the column named 'distance'\n",
    "\n",
    "                SELECT year, SUM(distance)/# as average_distance\n",
    "                                , COUNT(*) as #\n",
    "                FROM ...\n",
    "                WHERE WEAPON < 200\n",
    "                GROUP BY year\n",
    "                ORDER BY #\n",
    "\n",
    "\n",
    "        b)\n",
    "                SELECT police_station_name as division,\n",
    "                       SUM(distance)/# as average_distance,\n",
    "                       COUNT(*) as #\n",
    "                FROM ...\n",
    "                WHERE weapon NOT NULL\n",
    "                GROUP BY police_station_name\n",
    "                ORDER BY #\n",
    "\n",
    "    2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d8c250-8820-4bb9-84de-b83bd512fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    R = 6371\n",
    "    dLat = math.radians(lat2 - lat1)\n",
    "    dLon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dLat / 2) * math.sin(dLat / 2) + \\\n",
    "        math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dLon / 2) * math.sin(dLon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "haversine_udf = udf(haversine, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a08e7-d25b-4e9c-af0c-c33b7c15f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code for 4th query here\n",
    "# 1a)\n",
    "def query_4_1a(method = 'CONTINUE'):\n",
    "    start_time = time.time()\n",
    "    lapd_stations_new = lapd_stations.withColumnRenamed('PREC','AREA')\n",
    "    \n",
    "    if method == 'BROADCAST':\n",
    "        crime_data_join_stations = crime_data.withColumnRenamed('AREA ', 'AREA') \\\n",
    "                                    .join(broadcast(lapd_stations_new), 'AREA', 'inner')\n",
    "        crime_data_join_stations.explain()\n",
    "    elif method in ['MERGE', 'SHUFFLE_HASH', 'SHUFFLE_REPLICATE_NL']:\n",
    "        crime_data_join_stations = crime_data.withColumnRenamed('AREA ', 'AREA') \\\n",
    "                                    .hint(method).join(lapd_stations_new, 'AREA', 'inner')\n",
    "        crime_data_join_stations.explain()\n",
    "    elif method == 'CONTINUE':\n",
    "        crime_data_join_stations = crime_data.withColumnRenamed('AREA ', 'AREA') \\\n",
    "                                    .join(lapd_stations_new, 'AREA', 'inner')\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    crime_data_join_stations = crime_data_join_stations.withColumn('distance',\n",
    "                                    haversine_udf(col(\"LON\"), col(\"LAT\"), col(\"X\"), col(\"Y\")))\n",
    "    \n",
    "    crime_data_join_stations = crime_data_join_stations.withColumn('Weapon Used Cd', col('Weapon Used Cd').cast('int')) \\\n",
    "                                    .filter(col('Weapon Used Cd') < 200) \\\n",
    "                                    .withColumn('year', F.year('Date Rptd'))\n",
    "    \n",
    "    result = crime_data_join_stations.groupBy('year') \\\n",
    "        .agg((F.sum('distance') / F.count('*')).alias('average_distance'),\n",
    "            F.count('*').alias('#')) \\\n",
    "       .orderBy(F.col('year'))\n",
    "    \n",
    "    result.show()\n",
    "    end_time = time.time()\n",
    "    print(f'Method : {method} | Time {end_time - start_time}')\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1887d39-8279-4ee0-befe-2e1117b5d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b)\n",
    "def query_4_1b(method = 'CONTINUE'):\n",
    "    start_time = time.time()\n",
    "    lapd_stations_new = lapd_stations.withColumnRenamed('PREC','AREA')\n",
    "    \n",
    "    if method == 'BROADCAST':\n",
    "        crime_data_join_stations = crime_data.withColumnRenamed('AREA ', 'AREA') \\\n",
    "                                    .join(broadcast(lapd_stations_new), 'AREA', 'inner')\n",
    "        crime_data_join_stations.explain()\n",
    "        \n",
    "    elif method in ['MERGE', 'SHUFFLE_HASH', 'SHUFFLE_REPLICATE_NL']:\n",
    "        crime_data_join_stations = crime_data.withColumnRenamed('AREA ', 'AREA') \\\n",
    "                                    .hint(method).join(lapd_stations_new, 'AREA', 'inner')\n",
    "        crime_data_join_stations.explain()\n",
    "        \n",
    "    elif method == 'CONTINUE':\n",
    "        crime_data_join_stations = crime_data.withColumnRenamed('AREA ', 'AREA') \\\n",
    "                                    .join(lapd_stations_new, 'AREA', 'inner')\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    # distance of LAT and LON using Spark functions\n",
    "    crime_data_join_stations = crime_data_join_stations.withColumn('distance',\n",
    "                                    haversine_udf(col(\"LON\"), col(\"LAT\"), col(\"X\"), col(\"Y\"))) # Earths's radius\n",
    "    \n",
    "    crime_data_join_stations = crime_data_join_stations.withColumn('Weapon Used Cd', col('Weapon Used Cd').cast('int')) \\\n",
    "                                    .filter(F.col('Weapon Used Cd').isNotNull()) \\\n",
    "                                    .withColumn('year', F.year('Date Rptd'))\n",
    "    \n",
    "    result = crime_data_join_stations.groupBy('AREA NAME') \\\n",
    "        .agg(\n",
    "            (F.sum('distance') / F.count('*')).alias('average_distance'),\n",
    "            F.count('*').alias('#')\n",
    "        ) \\\n",
    "        .orderBy(F.col('#').desc()) \\\n",
    "        .withColumnRenamed('AREA NAME', 'division')\n",
    "    \n",
    "    result.show()\n",
    "    end_time = time.time()\n",
    "    print(f'Method : {method} | Time {end_time - start_time}')\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5b1f43-dd42-4ab4-89fc-100b2de20849",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987774a5-2c90-4679-9a1d-3b3d7f93864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a)\n",
    "def query_4_2a(method = 'CONTINUE'):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if method == 'BROADCAST':\n",
    "        combined_data = crime_data.hint(method).crossJoin(broadcast(lapd_stations))\n",
    "        combined_data.explain()\n",
    "        \n",
    "    elif method in ['MERGE', 'SHUFFLE_HASH', 'SHUFFLE_REPLICATE_NL']:\n",
    "        combined_data = crime_data.hint(method).crossJoin(lapd_stations)\n",
    "        combined_data.explain()\n",
    "        \n",
    "    elif method == 'CONTINUE':\n",
    "        combined_data = crime_data.crossJoin(lapd_stations)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # filter for DR_NO < 200  \n",
    "    # if lazy evaluation/optimizer doesnt do it by itself\n",
    "    \n",
    "    combined_data = combined_data.withColumn(\"closest_distance\", haversine_udf(col(\"LON\"), col(\"LAT\"), col(\"X\"), col(\"Y\")))\n",
    "    \n",
    "    windowSpec = Window.partitionBy(\"DR_NO\").orderBy(\"closest_distance\")\n",
    "    closest_stations = combined_data.withColumn(\"rank\", rank().over(windowSpec)).filter(col(\"rank\") == 1)\n",
    "    \n",
    "    final_data = closest_stations.select(col(\"DR_NO\"), col(\"DIVISION\").alias(\"closest_station\"), col(\"closest_distance\"))\n",
    "    \n",
    "    result = crime_data.join(final_data, \"DR_NO\")\n",
    "    crime_data_join_stations = result.withColumn('Weapon Used Cd', col('Weapon Used Cd').cast('int')) \\\n",
    "                                    .filter(col('Weapon Used Cd') < 200) \\\n",
    "                                    .withColumn('year', F.year('Date Rptd'))\n",
    "    \n",
    "    result = crime_data_join_stations.groupBy('year') \\\n",
    "        .agg((F.sum('closest_distance') / F.count('*')).alias('average_distance'),\n",
    "            F.count('*').alias('#')) \\\n",
    "       .orderBy(F.col('year'))\n",
    "\n",
    "    \n",
    "    result.show()\n",
    "    end_time = time.time()\n",
    "    print(f'Method : {method} | Time {end_time - start_time}')\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27dfc9d-94e5-4d8c-874a-7a6872692fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a)\n",
    "def query_4_2b(method = 'CONTINUE'):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if method == 'BROADCAST':\n",
    "        combined_data = crime_data.hint(method).crossJoin(broadcast(lapd_stations))\n",
    "        combined_data.explain()\n",
    "        \n",
    "    elif method in ['MERGE', 'SHUFFLE_HASH', 'SHUFFLE_REPLICATE_NL']:\n",
    "        combined_data = crime_data.hint(method).crossJoin(lapd_stations)\n",
    "        combined_data.explain()\n",
    "        \n",
    "    elif method == 'CONTINUE':\n",
    "        combined_data = crime_data.crossJoin(lapd_stations)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    \n",
    "    combined_data = combined_data.withColumn(\"closest_distance\", haversine_udf(col(\"LON\"), col(\"LAT\"), col(\"X\"), col(\"Y\")))\n",
    "    \n",
    "    windowSpec = Window.partitionBy(\"DR_NO\").orderBy(\"closest_distance\")\n",
    "    closest_stations = combined_data.withColumn(\"rank\", rank().over(windowSpec)).filter(col(\"rank\") == 1)\n",
    "    \n",
    "    final_data = closest_stations.select(col(\"DR_NO\"), col(\"DIVISION\").alias(\"closest_station\"), col(\"closest_distance\"))\n",
    "    \n",
    "    result = crime_data.join(final_data, \"DR_NO\")\n",
    "    crime_data_join_stations = result.withColumn('Weapon Used Cd', col('Weapon Used Cd').cast('int')) \\\n",
    "                                    .filter(F.col('Weapon Used Cd').isNotNull()) \\\n",
    "                                    .withColumn('year', F.year('Date Rptd'))\n",
    "    \n",
    "    result = crime_data_join_stations.groupBy('AREA NAME') \\\n",
    "        .agg(\n",
    "            (F.sum('closest_distance') / F.count('*')).alias('average_distance'),\n",
    "            F.count('*').alias('#')\n",
    "        ) \\\n",
    "        .orderBy(F.col('#').desc()) \\\n",
    "        .withColumnRenamed('AREA NAME', 'division')\n",
    "    \n",
    "    result.show()\n",
    "    end_time = time.time()\n",
    "    print(f'Method : {method} | Time {end_time - start_time}')\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc31421-b725-4649-8b65-5f6308026e91",
   "metadata": {},
   "source": [
    "# Query 1 on 4 Executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175a3f8-6285-4e40-8abe-f4d64c010ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1_Dataframe_API()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d0ad43-b4f9-4843-ae89-c2f49b003d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1_SQL_API()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e5649-89cf-4d22-bcca-f0c76f039ddf",
   "metadata": {},
   "source": [
    "# Query 2 on 4 Executors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98250c68-967e-46d6-a097-cf0e07c9b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2_Dataframe_API()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b4d4b6-a5ca-4d86-93c0-72355d45a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2_rdd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a199f4e-af1a-4044-aba1-9de3e6dcd2f1",
   "metadata": {},
   "source": [
    "# Query 3 on 4 Executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e344e-6eab-480b-b6f8-920f5a78291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6323b9-6b57-475f-8595-aaaeb1223108",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in ['BROADCAST','MERGE', 'SHUFFLE_HASH']:\n",
    "    query_3(method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cfaa40-3215-4fb1-9c20-d6e1831c26ba",
   "metadata": {},
   "source": [
    "# Query 4 on 4 Executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f3227-7e31-41ce-9fe2-3ad13c94bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_4_1a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c2627-39c0-4a25-aedc-b45189117425",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_4_1b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fccae6-016c-4a45-8a07-888ea44ae9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_4_2a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2029fb8d-319d-4e31-a8e6-69b97c06722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_4_2b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a9b5b2-94ae-4cb5-80d2-cb8f8775152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in ['BROADCAST','MERGE', 'SHUFFLE_HASH']:\n",
    "    query_4_1a(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ffad6f-3f43-4660-98ff-44ff85fd42c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in ['BROADCAST','MERGE', 'SHUFFLE_HASH']:\n",
    "    query_4_1b(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15089bd1-65f3-47b0-a2ae-1b1e5030aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in ['BROADCAST','MERGE', 'SHUFFLE_HASH']:\n",
    "    query_4_2a(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d14338-4bda-41cb-b43d-5731af568ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in ['BROADCAST','MERGE', 'SHUFFLE_HASH']:\n",
    "    query_4_2b(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08674079-e23f-46b1-b5b9-30c9c3f868a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
