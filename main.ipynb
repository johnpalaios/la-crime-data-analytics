{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56c50ab-5769-4e7d-946c-ec870888801c",
   "metadata": {},
   "source": [
    "#### Useful Links \n",
    "- Spark History Server : http://83.212.73.248:18080/\n",
    "- Hadoop YARN (scheduler) : http://83.212.73.248:8088/cluster\n",
    "- HDFS : http://83.212.73.248:9870/dfshealth.html#tab-overview\n",
    "\n",
    "#### Useful Commands : \n",
    "- Connect to okeanos-master (from local) : `$ ssh user@snf-40202.ok-kno.grnetcloud.net `\n",
    "    - Password : 'Rand0m'\n",
    "- Connect to okeanos-worker (from okeanos-master) : `$ ssh okeanos-worker`\n",
    "- Open Jupyter Notebook : `$ jupyter notebook --ip 83.212.73.248 --port 8888`\n",
    "\n",
    "#### Thinks to do :\n",
    "- Make the data Csv to Parquet\n",
    "- Make those columns the type we want\n",
    "- Write the Queries (!)\n",
    "- Benchmark and optimize them etc.\n",
    "- Balance the data onto HDFS across the two datanodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c667a612-a781-4680-bb05-0fdfe7aed047",
   "metadata": {},
   "source": [
    "### Full HDFS path is here : hdfs://okeanos-master:54310/csv_data/\n",
    "and contains :  \n",
    "     \n",
    "     1.  hdfs://okeanos-master:54310/csv_data/LAPD_Police_Stations.csv\n",
    "     2.  hdfs://okeanos-master:54310/csv_data/crime_data_2019.csv \n",
    "     3.  hdfs://okeanos-master:54310/csv_data/crime_data_2023.csv\n",
    "     4.  hdfs://okeanos-master:54310/csv_data/revgecoding.csv \n",
    "     5.  hdfs://okeanos-master:54310/csv_data/income/\n",
    "         1. LA_income_2015.csv\n",
    "         2. LA_income_2017.csv\n",
    "         3. LA_income_2019.csv\n",
    "         4. LA_income_2021.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a4e254-eda8-4782-a680-a9fc5c1d69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyspark Imports\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import col, regexp_replace\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from operator import add\n",
    "import geopy.distance\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, rank\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.window import Window\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbb858d-c65c-40f6-93c8-eae9504bbf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/12 15:48:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/01/12 15:48:34 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "# initialize sparkSession, make the data from csv to parquet,\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"4 Executors\") \\\n",
    "    .config(\"spark.driver.memory\", \"1g\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efaaacbe-53a0-4f5d-bf6f-f6eb6c42e3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# load data into memory, do the necessary joins etc. here\n",
    "crime_data = spark.read.parquet(\"hdfs://okeanos-master:54310/parquet/crime_data_*.parquet\")\n",
    "revge = spark.read.parquet(\"hdfs://okeanos-master:54310/parquet/revgecoding.parquet\")\n",
    "# only 2015 income data needed\n",
    "income = spark.read \\\n",
    "            .parquet(\"hdfs://okeanos-master:54310/parquet/income/LA_income_2015.parquet\")\n",
    "lapd_stations = spark.read.parquet(\"hdfs://okeanos-master:54310/parquet/LAPD_Police_Stations.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b586a4fc-878b-4370-91e1-36faca721379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crime_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0098ff2-3857-4604-8d16-5c26d003759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crime_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ad4d5-4e37-41a5-8833-7b3969368d31",
   "metadata": {},
   "source": [
    "#### Change Column Types \n",
    "Στην εκφωνηση λέει : Διατηρώντας τα αρχικά ονόματα στηλών \n",
    "\n",
    "εννοωντας οτι δεν μπορουμε να κανουμε το 'Date Rptd' -> 'Date_Rptd' ?\n",
    "- Date Rptd: date\n",
    "- DATE OCC: date\n",
    "- Vict Age: integer\n",
    "- LAT: double\n",
    "- LON: double\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b85974b-2551-4dda-859a-e86e3011dcea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# code for column type changing\n",
    "crime_data = crime_data.withColumn(\"Date Rptd\", to_timestamp(\"Date Rptd\", 'MM/dd/yyyy hh:mm:ss a')) \\\n",
    "    .withColumn(\"DATE OCC\", to_timestamp(\"DATE OCC\", 'MM/dd/yyyy hh:mm:ss a')) \\\n",
    "    .withColumn(\"Vict Age\", col(\"Vict Age\").cast(\"int\")) \\\n",
    "    .withColumn(\"LAT\", col(\"LAT\").cast(\"double\")) \\\n",
    "    .withColumn(\"LON\", col(\"LON\").cast(\"double\")) \\\n",
    "    .withColumn(\"Premis_Desc\", col(\"Premis Desc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7729edb-fff8-4a31-b7bd-4dd61a4ea834",
   "metadata": {},
   "source": [
    "# 1st Query :\r\n",
    "        find\r\n",
    "            for each year\r\n",
    "                the 3 months with the biggest crime count\r\n",
    "\r\n",
    "        year | month | crime_total (count)  + #order\r\n",
    "        dataframe.show()\r\n",
    "\r\n",
    "        SELECT  YEAR(date_rptd) as year,\r\n",
    "                MONTH(date_rptd) as month,\r\n",
    "                COUNT(*) as crime_total,\r\n",
    "                ROW_NUMBER() OVER (PARTITION BY year ORDER BY crime_total) as '#'\r\n",
    "        GROUP BY YEAR(date_rptd), MONTH(date_rptd)\r\n",
    "        SORT BY year ASC, crime_total DESp    GROUP BY police_station_name\r\n",
    "                ORDER BY #\r\n",
    "\r\n",
    "    2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db03eee5-f317-4051-b526-4092b7522187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for first query in SQL API\n",
    "def query_1_SQL_API():\n",
    "    start_time = time.time()\n",
    "    crime_data.createOrReplaceTempView(\"crime_data\")\n",
    "    \n",
    "    query = \"\"\"\n",
    "        SELECT * FROM (\n",
    "            SELECT \n",
    "                year(`Date Rptd`) AS year,\n",
    "                month(`Date Rptd`) AS month,\n",
    "                COUNT(*) AS crime_total,\n",
    "                ROW_NUMBER() OVER (PARTITION BY year(`Date Rptd`) ORDER BY COUNT(*) DESC) AS rank\n",
    "            FROM \n",
    "                crime_data\n",
    "            GROUP BY \n",
    "                year(`Date Rptd`), month(`Date Rptd`)\n",
    "        ) ranked_data\n",
    "        WHERE rank <= 3\n",
    "        ORDER BY year, rank\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    result_df = spark.sql(query)\n",
    "    \n",
    "    result_df.show()\n",
    "    end_time = time.time()\n",
    "    \n",
    "    result_df.explain()\n",
    "\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39898c69-f992-45c8-a534-8ee164828c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for first query in Dataframe API\n",
    "def query_1_Dataframe_API():\n",
    "    start_time = time.time()\n",
    "    crime_counts = crime_data.withColumn(\"year\", F.year(\"Date Rptd\")) \\\n",
    "                          .withColumn(\"month\", F.month(\"Date Rptd\")) \\\n",
    "                          .groupBy(\"year\", \"month\") \\\n",
    "                          .agg(F.count(\"*\").alias(\"crime_total\"))\n",
    "    \n",
    "    window_spec = Window.partitionBy(\"year\").orderBy(F.desc(\"crime_total\"))\n",
    "    \n",
    "    ranked_crime = crime_counts.withColumn(\"rank\", F.row_number().over(window_spec))\n",
    "    \n",
    "    result_df = ranked_crime.filter(\"rank <= 3\").orderBy(\"year\", \"rank\")\n",
    "    \n",
    "    result_df.show()\n",
    "    end_time = time.time()\n",
    "\n",
    "    result_df.explain()\n",
    "\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55eda9-3400-4cf9-a5a8-2247792fd456",
   "metadata": {},
   "source": [
    " # 2nd Query :\n",
    "\n",
    "\n",
    "            SELECT street,\n",
    "                   CASE\n",
    "                      WHEN HOUR('Date Rptd') BETWEEN 5 AND 11 THEN 'Morning'\n",
    "                      WHEN HOUR('Date Rptd') BETWEEN 12 AND 16 THEN 'Noon'\n",
    "                      WHEN HOUR('Date Rptd') BETWEEN 17 AND 20 THEN 'Afternoon'\n",
    "                      ELSE 'Night'\n",
    "                    END AS time_group,\n",
    "                    COUNT(*) as count\n",
    "            WHERE 'Prem Desc'='STREET'\n",
    "            GROUP BY time_group\n",
    "            ORDER BY count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ab6c1df-26e6-4b93-b9ee-a2d5cff7a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code for 2nd query here for Dataframe/SQL API\n",
    "def query_2_Dataframe_API():\n",
    "    start_time = time.time()\n",
    "    filtered_df = crime_data.filter(crime_data['Premis_Desc'] == 'STREET')\n",
    "\n",
    "    time_group_df = filtered_df.withColumn(\"time_group\",\n",
    "                                       # TIME OCC is in 24 hour military time integer values\n",
    "                                      F.when((F.col('TIME OCC').between(500, 1159)), 'Morning')\n",
    "                                      .when((F.col('TIME OCC').between(1200, 1659)), 'Noon')\n",
    "                                      .when((F.col('TIME OCC').between(1700, 2059)), 'Afternoon')\n",
    "                                      .otherwise('Night'))\n",
    "\n",
    "    result_df = time_group_df.groupBy(\"time_group\").agg(F.count(\"*\").alias(\"count\"))\n",
    "\n",
    "    result_df = result_df.orderBy(col(\"count\").desc())\n",
    "    result_df.show()\n",
    "    end_time = time.time()\n",
    "    # call explain() method in order\n",
    "    # to see the query's physical plan\n",
    "    # and improve the RDD query\n",
    "    result_df.explain()\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "339e48bb-fb2f-4a6a-acca-c11c76786357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code for 2nd query here for RDD API\n",
    "def time_segs(row):\n",
    "    if 500 <= int(row['TIME OCC']) <= 1159:\n",
    "        return 'Morning'\n",
    "    elif 1200 <= int(row['TIME OCC']) <= 1659:\n",
    "        return 'Noon'\n",
    "    elif 1700 <= int(row['TIME OCC']) <= 2059:\n",
    "        return 'Afternoon'\n",
    "    else:\n",
    "        return 'Night'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f928f8cf-9407-4a3c-b0cc-836e78e49b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_2_rdd(): \n",
    "    start_time = time.time()\n",
    "    crime_data_rdd = crime_data.rdd.filter(lambda x: x['Premis_Desc'] == 'STREET') \\\n",
    "                                .map(lambda x: (time_segs(x),1)) \\\n",
    "                                .reduceByKey(lambda k1,k2: k1+k2) \\\n",
    "                                .sortBy(lambda x: x[1], ascending = False)\n",
    "    \n",
    "    result = crime_data_rdd.collect()\n",
    "    for time_of_day, count in result:\n",
    "        print(f\"{time_of_day}: {count}\")\n",
    "        \n",
    "    end_time = time.time()\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c51ced-8b88-4c16-ad21-0b1479e9b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_time_group(row):\n",
    "    time_occ = int(row)\n",
    "    if 500 <= time_occ <= 1159:\n",
    "        return 'Morning'\n",
    "    elif 1200 <= time_occ <= 1659:\n",
    "        return 'Noon'\n",
    "    elif 1700 <= time_occ <= 2059:\n",
    "        return 'Afternoon'\n",
    "    else:\n",
    "        return 'Night'\n",
    "        \n",
    "def query_2_rdd_new():\n",
    "    start_time = time.time()\n",
    "\n",
    "    crime_data_rdd = crime_data.rdd.filter(lambda x: x['Premis_Desc'] == 'STREET') \\\n",
    "                                .map(lambda x: (map_time_group(x['TIME OCC']), 1)) \\\n",
    "                                .reduceByKey(add).sortBy(lambda x: x[1], ascending = False)\n",
    "\n",
    "    result = crime_data_rdd.collect()\n",
    "    for time_of_day, count in result:\n",
    "        print(f\"{time_of_day}: {count}\")\n",
    "        \n",
    "    end_time = time.time()\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "990b45bf-c7a1-4f7d-8a85-e8b7827380fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_2_rdd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc4ad40f-c002-49d6-bc68-230131410474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c962e-49f3-4409-aa0e-3b113c973570",
   "metadata": {},
   "source": [
    "# 3rd Query :\n",
    "\n",
    "        find the 3 zip codes with min and max household income\n",
    "                    |\n",
    "                    |\n",
    "                    v\n",
    "        // filter(remove) victimless crimes\n",
    "                    |\n",
    "                    |\n",
    "                    v\n",
    "        select vict_desc, COUNT(*) as count\n",
    "        where year=2015\n",
    "        group by vict_desc\n",
    "        order by count DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c006e0c2-4c2d-4541-ac68-10bad330ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code for 3rd query here\n",
    "def query_3(method = 'CONTINUE'):\n",
    "    start_time = time.time()\n",
    "    #crime_data_2015 = crime_data.filter(year(col('Date Rptd')) == 2015)\n",
    "    if method == 'BROADCAST':\n",
    "        crime_data_join_revge = crime_data.join(broadcast(revge), ['LAT', 'LON'], 'inner') \\\n",
    "            .withColumnRenamed('ZIPcode', 'Zip Code') \\\n",
    "            .withColumn(\"Zip Code\", col(\"Zip Code\").cast(\"int\")) \\\n",
    "            .filter((col('Vict Descent') != 'X') & (col('Vict Sex') != 'X'))\n",
    "        #crime_data_join_revge.explain()\n",
    "        \n",
    "    elif method in ['MERGE', 'SHUFFLE_HASH', 'SHUFFLE_REPLICATE_NL']:\n",
    "        crime_data_join_revge = crime_data.hint(method).join(revge, ['LAT', 'LON'], 'inner') \\\n",
    "            .withColumnRenamed('ZIPcode', 'Zip Code') \\\n",
    "            .withColumn(\"Zip Code\", col(\"Zip Code\").cast(\"int\")) \\\n",
    "            .filter((col('Vict Descent') != 'X') & (col('Vict Sex') != 'X'))\n",
    "        #crime_data_join_revge.explain()\n",
    "        \n",
    "    elif method == 'CONTINUE':\n",
    "        crime_data_join_revge = crime_data.join(revge, ['LAT', 'LON'], 'inner') \\\n",
    "            .withColumnRenamed('ZIPcode', 'Zip Code') \\\n",
    "            .withColumn(\"Zip Code\", col(\"Zip Code\").cast(\"int\")) \\\n",
    "            .filter((col('Vict Descent') != 'X') & (col('Vict Sex') != 'X'))\n",
    "        \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    #crime_data_join_revge = crime_data.join(revge, ['LAT', 'LON'], 'inner') \\\n",
    "    #    .withColumnRenamed('ZIPcode', 'Zip Code') \\\n",
    "    #    .withColumn(\"Zip Code\", col(\"Zip Code\").cast(\"int\")) \\\n",
    "    #    .filter((col('Vict Descent') != 'X') & (col('Vict Sex') != 'X'))\n",
    "    \n",
    "    crime_data_join_income = crime_data_join_revge.join(income, 'Zip Code', 'inner') \\\n",
    "                                .withColumn('Estimated Median Income', \n",
    "                                            regexp_replace(col('Estimated Median Income'), '[$,]', '')) \\\n",
    "                                .withColumn('Estimated Median Income', \n",
    "                                            col('Estimated Median Income') \\\n",
    "                                .cast('double'))\n",
    "    \n",
    "    max_income_zip_codes = crime_data_join_income.groupBy('Zip Code') \\\n",
    "                            .agg({'Estimated Median Income': 'max'}) \\\n",
    "                            .withColumnRenamed('max(Estimated Median Income)', 'MaxIncome') \\\n",
    "                            .orderBy(col('MaxIncome').desc()) \\\n",
    "                            .limit(3)\n",
    "    \n",
    "    min_income_zip_codes = crime_data_join_income.groupBy('Zip Code') \\\n",
    "                            .agg({'Estimated Median Income': 'min'}) \\\n",
    "                            .withColumnRenamed('min(Estimated Median Income)', 'MinIncome') \\\n",
    "                            .orderBy(col('MinIncome')) \\\n",
    "                            .limit(3)\n",
    "    \n",
    "    zip_codes = min_income_zip_codes.union(max_income_zip_codes)\n",
    "    \n",
    "    zip_codes_list = [row['Zip Code'] for row in zip_codes.collect()]\n",
    "    \n",
    "    result = crime_data_join_income \\\n",
    "                .filter(col('Zip Code').isin(zip_codes_list)) \\\n",
    "                .filter(year(col('Date Rptd')) == 2015) \\\n",
    "                .groupBy('Vict Descent') \\\n",
    "                .count() \\\n",
    "                .withColumnRenamed('count', '#') \\\n",
    "                .orderBy(col('#').desc())\n",
    "    \n",
    "    result.show()\n",
    "    end_time = time.time()\n",
    "    result.explain()\n",
    "    print(f'Method : {method} | Time {end_time - start_time}')\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0eefbc50-5aff-49e3-850e-f646dfde1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_3(\"SHUFFLE_HASH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06b66b81-6415-4e00-be9b-5fcec3537f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54d07b41-53fe-4ad7-8b80-9efa43bbcacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for method in ['BROADCAST','MERGE', 'SHUFFLE_HASH']:\n",
    "#    query_3(method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48047e1-8739-48ef-86b3-1cc547d2beb1",
   "metadata": {},
   "source": [
    "# 4th Query :\n",
    "    1 :\n",
    "        a)\n",
    "                make_extra_columns() : distance of police stations from crime\n",
    "                join crime_table with LA Police Stations on police_station\n",
    "                and add column of police station\n",
    "                for each row compute distance from two coordinates                         \n",
    "                put this computed distance in the column named 'distance'\n",
    "\n",
    "                SELECT year, SUM(distance)/# as average_distance\n",
    "                                , COUNT(*) as #\n",
    "                FROM ...\n",
    "                WHERE WEAPON < 200\n",
    "                GROUP BY year\n",
    "                ORDER BY #\n",
    "\n",
    "\n",
    "        b)\n",
    "                SELECT police_station_name as division,\n",
    "                       SUM(distance)/# as average_distance,\n",
    "                       COUNT(*) as #\n",
    "                FROM ...\n",
    "                WHERE weapon NOT NULL\n",
    "                GROUP BY police_station_name\n",
    "                ORDER BY #\n",
    "\n",
    "    2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4d8c250-8820-4bb9-84de-b83bd512fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance on a sphere (as earth is not flat)\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    R = 6371\n",
    "    dLat = math.radians(lat2 - lat1)\n",
    "    dLon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dLat / 2) * math.sin(dLat / 2) + \\\n",
    "        math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dLon / 2) * math.sin(dLon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "haversine_udf = udf(haversine, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "505a08e7-d25b-4e9c-af0c-c33b7c15f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code for 4th query here\n",
    "# 1a)\n",
    "def query_4_1a(method = 'CONTINUE'):\n",
    "    start_time = time.time()\n",
    "    lapd_stations_new = lapd_stations.withColumnRenamed('PREC','AREA')\n",
    "    \n",
    "    if method == 'BROADCAST':\n",
    "        crime_data_join_stations = crime_data.withColumnRenamed('AREA ', 'AREA') \\\n",
    "                                    .join(broadcast(lapd_stations_new), 'AREA', 'inner')\n",
    "    elif method in ['MERGE', 'SHUFFLE_HASH', 'SHUFFLE_REPLICATE_NL']:\n",
    "        crime_data_join_stations = crime_data.withColumnRenamed('AREA ', 'AREA') \\\n",
    "                                    .hint(method).join(lapd_stations_new, 'AREA', 'inner')\n",
    "    elif method == 'CONTINUE':\n",
    "        crime_data_join_stations = crime_data.withColumnRenamed('AREA ', 'AREA') \\\n",
    "                                    .join(lapd_stations_new, 'AREA', 'inner')\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    crime_data_join_stations = crime_data_join_stations.withColumn('distance',\n",
    "                                    haversine_udf(col(\"LON\"), col(\"LAT\"), col(\"X\"), col(\"Y\")))\n",
    "    \n",
    "    crime_data_join_stations = crime_data_join_stations.withColumn('Weapon Used Cd', col('Weapon Used Cd').cast('int')) \\\n",
    "                                    .filter(col('Weapon Used Cd') < 200) \\\n",
    "                                    .withColumn('year', F.year('Date Rptd'))\n",
    "    \n",
    "    result = crime_data_join_stations.groupBy('year') \\\n",
    "        .agg((F.sum('distance') / F.count('*')).alias('average_distance'),\n",
    "            F.count('*').alias('#')) \\\n",
    "       .orderBy(F.col('year'))\n",
    "    \n",
    "    result.show()\n",
    "    end_time = time.time()\n",
    "    result.explain()\n",
    "    print(f'Method : {method} | Time {end_time - start_time}')\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1887d39-8279-4ee0-befe-2e1117b5d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b)\n",
    "def query_4_1b(method = 'CONTINUE'):\n",
    "    start_time = time.time()\n",
    "    lapd_stations_new = lapd_stations.withColumnRenamed('PREC','AREA')\n",
    "    \n",
    "    if method == 'BROADCAST':\n",
    "        crime_data_join_stations = crime_data.withColumnRenamed('AREA ', 'AREA') \\\n",
    "                                    .join(broadcast(lapd_stations_new), 'AREA', 'inner')\n",
    "    elif method in ['MERGE', 'SHUFFLE_HASH', 'SHUFFLE_REPLICATE_NL']:\n",
    "        crime_data_join_stations = crime_data.withColumnRenamed('AREA ', 'AREA') \\\n",
    "                                    .hint(method).join(lapd_stations_new, 'AREA', 'inner')\n",
    "    elif method == 'CONTINUE':\n",
    "        crime_data_join_stations = crime_data.withColumnRenamed('AREA ', 'AREA') \\\n",
    "                                    .join(lapd_stations_new, 'AREA', 'inner')\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    # distance of LAT and LON using Spark functions\n",
    "    crime_data_join_stations = crime_data_join_stations.withColumn('distance',\n",
    "                                    haversine_udf(col(\"LON\"), col(\"LAT\"), col(\"X\"), col(\"Y\"))) # Earths's radius\n",
    "    \n",
    "    crime_data_join_stations = crime_data_join_stations.withColumn('Weapon Used Cd', col('Weapon Used Cd').cast('int')) \\\n",
    "                                    .filter(F.col('Weapon Used Cd').isNotNull()) \\\n",
    "                                    .withColumn('year', F.year('Date Rptd'))\n",
    "    \n",
    "    result = crime_data_join_stations.groupBy('AREA NAME') \\\n",
    "        .agg(\n",
    "            (F.sum('distance') / F.count('*')).alias('average_distance'),\n",
    "            F.count('*').alias('#')\n",
    "        ) \\\n",
    "        .orderBy(F.col('#').desc()) \\\n",
    "        .withColumnRenamed('AREA NAME', 'division')\n",
    "    \n",
    "    result.show()\n",
    "    end_time = time.time()\n",
    "    result.explain()\n",
    "    print(f'Method : {method} | Time {end_time - start_time}')\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c5b1f43-dd42-4ab4-89fc-100b2de20849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DR_NO: integer (nullable = true)\n",
      " |-- Date Rptd: timestamp (nullable = true)\n",
      " |-- DATE OCC: timestamp (nullable = true)\n",
      " |-- TIME OCC: integer (nullable = true)\n",
      " |-- AREA : integer (nullable = true)\n",
      " |-- AREA NAME: string (nullable = true)\n",
      " |-- Rpt Dist No: integer (nullable = true)\n",
      " |-- Part 1-2: integer (nullable = true)\n",
      " |-- Crm Cd: integer (nullable = true)\n",
      " |-- Crm Cd Desc: string (nullable = true)\n",
      " |-- Mocodes: string (nullable = true)\n",
      " |-- Vict Age: integer (nullable = true)\n",
      " |-- Vict Sex: string (nullable = true)\n",
      " |-- Vict Descent: string (nullable = true)\n",
      " |-- Premis Cd: integer (nullable = true)\n",
      " |-- Premis Desc: string (nullable = true)\n",
      " |-- Weapon Used Cd: integer (nullable = true)\n",
      " |-- Weapon Desc: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Status Desc: string (nullable = true)\n",
      " |-- Crm Cd 1: integer (nullable = true)\n",
      " |-- Crm Cd 2: integer (nullable = true)\n",
      " |-- Crm Cd 3: integer (nullable = true)\n",
      " |-- Crm Cd 4: integer (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      " |-- Cross Street: string (nullable = true)\n",
      " |-- LAT: double (nullable = true)\n",
      " |-- LON: double (nullable = true)\n",
      " |-- Premis_Desc: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crime_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "987774a5-2c90-4679-9a1d-3b3d7f93864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a)\n",
    "def query_4_2a(method = 'CONTINUE'):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if method == 'BROADCAST':\n",
    "        combined_data = crime_data.hint(method).crossJoin(broadcast(lapd_stations))        \n",
    "    elif method in ['MERGE', 'SHUFFLE_HASH', 'SHUFFLE_REPLICATE_NL']:\n",
    "        combined_data = crime_data.hint(method).crossJoin(lapd_stations)\n",
    "    elif method == 'CONTINUE':\n",
    "        combined_data = crime_data.crossJoin(lapd_stations)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    # filter for DR_NO < 200  \n",
    "    # or Catalyst Optimizer does it by itself \n",
    "    \n",
    "    combined_data = combined_data.withColumn(\"closest_distance\", haversine_udf(col(\"LON\"), col(\"LAT\"), col(\"X\"), col(\"Y\")))\n",
    "    \n",
    "    windowSpec = Window.partitionBy(\"DR_NO\").orderBy(\"closest_distance\")\n",
    "    closest_stations = combined_data.withColumn(\"rank\", rank().over(windowSpec)).filter(col(\"rank\") == 1)\n",
    "    \n",
    "    final_data = closest_stations.select(col(\"DR_NO\"), col(\"DIVISION\").alias(\"closest_station\"), col(\"closest_distance\"))\n",
    "    \n",
    "    result = crime_data.join(final_data, \"DR_NO\")\n",
    "    crime_data_join_stations = result.withColumn('Weapon Used Cd', col('Weapon Used Cd').cast('int')) \\\n",
    "                                    .filter(col('Weapon Used Cd') < 200) \\\n",
    "                                    .withColumn('year', F.year('Date Rptd'))\n",
    "    \n",
    "    result = crime_data_join_stations.groupBy('year') \\\n",
    "        .agg((F.sum('closest_distance') / F.count('*')).alias('average_distance'),\n",
    "            F.count('*').alias('#')) \\\n",
    "       .orderBy(F.col('year'))\n",
    "\n",
    "    \n",
    "    result.show()\n",
    "    end_time = time.time()\n",
    "    result.explain()\n",
    "    print(f'Method : {method} | Time {end_time - start_time}')\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c27dfc9d-94e5-4d8c-874a-7a6872692fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b)\n",
    "def query_4_2b(method = 'CONTINUE'):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if method == 'BROADCAST':\n",
    "        combined_data = crime_data.hint(method).crossJoin(broadcast(lapd_stations))\n",
    "    elif method in ['MERGE', 'SHUFFLE_HASH', 'SHUFFLE_REPLICATE_NL']:\n",
    "        combined_data = crime_data.hint(method).crossJoin(lapd_stations)        \n",
    "    elif method == 'CONTINUE':\n",
    "        combined_data = crime_data.crossJoin(lapd_stations)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    \n",
    "    combined_data = combined_data.withColumn(\"closest_distance\", haversine_udf(col(\"LON\"), col(\"LAT\"), col(\"X\"), col(\"Y\")))\n",
    "    \n",
    "    windowSpec = Window.partitionBy(\"DR_NO\").orderBy(\"closest_distance\")\n",
    "    closest_stations = combined_data.withColumn(\"rank\", rank().over(windowSpec)).filter(col(\"rank\") == 1)\n",
    "    \n",
    "    final_data = closest_stations.select(col(\"DR_NO\"), col(\"DIVISION\").alias(\"closest_station\"), col(\"closest_distance\"))\n",
    "    \n",
    "    result = crime_data.join(final_data, \"DR_NO\")\n",
    "    crime_data_join_stations = result.withColumn('Weapon Used Cd', col('Weapon Used Cd').cast('int')) \\\n",
    "                                    .filter(F.col('Weapon Used Cd').isNotNull()) \\\n",
    "                                    .withColumn('year', F.year('Date Rptd'))\n",
    "    \n",
    "    result = crime_data_join_stations.groupBy('AREA NAME') \\\n",
    "        .agg(\n",
    "            (F.sum('closest_distance') / F.count('*')).alias('average_distance'),\n",
    "            F.count('*').alias('#')\n",
    "        ) \\\n",
    "        .orderBy(F.col('#').desc()) \\\n",
    "        .withColumnRenamed('AREA NAME', 'division')\n",
    "    \n",
    "    result.show()\n",
    "    end_time = time.time()\n",
    "    result.explain()\n",
    "    print(f'Method : {method} | Time {end_time - start_time}')\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc31421-b725-4649-8b65-5f6308026e91",
   "metadata": {},
   "source": [
    "# Query 1 on 4 Executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1aedf41-fde4-4afb-b669-a85ff36c9bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DR_NO: int, Date Rptd: timestamp, DATE OCC: timestamp, TIME OCC: int, AREA : int, AREA NAME: string, Rpt Dist No: int, Part 1-2: int, Crm Cd: int, Crm Cd Desc: string, Mocodes: string, Vict Age: int, Vict Sex: string, Vict Descent: string, Premis Cd: int, Premis Desc: string, Weapon Used Cd: int, Weapon Desc: string, Status: string, Status Desc: string, Crm Cd 1: int, Crm Cd 2: int, Crm Cd 3: int, Crm Cd 4: int, LOCATION: string, Cross Street: string, LAT: double, LON: double, Premis_Desc: string]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " crime_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2175a3f8-6285-4e40-8abe-f4d64c010ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+----+\n",
      "|year|month|crime_total|rank|\n",
      "+----+-----+-----------+----+\n",
      "|2010|    3|      17595|   1|\n",
      "|2010|    7|      17520|   2|\n",
      "|2010|    5|      17338|   3|\n",
      "|2011|    8|      17139|   1|\n",
      "|2011|    5|      17050|   2|\n",
      "|2011|    3|      16951|   3|\n",
      "|2012|    8|      17696|   1|\n",
      "|2012|   10|      17477|   2|\n",
      "|2012|    5|      17391|   3|\n",
      "|2013|    8|      17329|   1|\n",
      "|2013|    7|      16714|   2|\n",
      "|2013|    5|      16671|   3|\n",
      "|2014|    7|      14059|   1|\n",
      "|2014|   10|      14031|   2|\n",
      "|2014|    9|      13799|   3|\n",
      "|2015|    8|      18951|   1|\n",
      "|2015|   10|      18916|   2|\n",
      "|2015|    7|      18528|   3|\n",
      "|2016|    8|      19779|   1|\n",
      "|2016|   10|      19615|   2|\n",
      "+----+-----+-----------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [year#514 ASC NULLS FIRST, rank#614 ASC NULLS FIRST], true, 0\n",
      "   +- Exchange rangepartitioning(year#514 ASC NULLS FIRST, rank#614 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=308]\n",
      "      +- Filter (rank#614 <= 3)\n",
      "         +- Window [row_number() windowspecdefinition(year#514, crime_total#609L DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank#614], [year#514], [crime_total#609L DESC NULLS LAST]\n",
      "            +- WindowGroupLimit [year#514], [crime_total#609L DESC NULLS LAST], row_number(), 3, Final\n",
      "               +- Sort [year#514 ASC NULLS FIRST, crime_total#609L DESC NULLS LAST], false, 0\n",
      "                  +- Exchange hashpartitioning(year#514, 200), ENSURE_REQUIREMENTS, [plan_id=302]\n",
      "                     +- WindowGroupLimit [year#514], [crime_total#609L DESC NULLS LAST], row_number(), 3, Partial\n",
      "                        +- Sort [year#514 ASC NULLS FIRST, crime_total#609L DESC NULLS LAST], false, 0\n",
      "                           +- HashAggregate(keys=[year#514, month#545], functions=[count(1)])\n",
      "                              +- Exchange hashpartitioning(year#514, month#545, 200), ENSURE_REQUIREMENTS, [plan_id=296]\n",
      "                                 +- HashAggregate(keys=[year#514, month#545], functions=[partial_count(1)])\n",
      "                                    +- Project [year(cast(Date Rptd#194 as date)) AS year#514, month(cast(Date Rptd#194 as date)) AS month#545]\n",
      "                                       +- InMemoryTableScan [Date Rptd#194]\n",
      "                                             +- InMemoryRelation [DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                                                   +- *(1) Project [DR_NO#0, gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS Date Rptd#194, gettimestamp(DATE OCC#2, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#11, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "                                                      +- *(1) ColumnarToRow\n",
      "                                                         +- FileScan parquet [DR_NO#0,Date Rptd#1,DATE OCC#2,TIME OCC#3,AREA #4,AREA NAME#5,Rpt Dist No#6,Part 1-2#7,Crm Cd#8,Crm Cd Desc#9,Mocodes#10,Vict Age#11,Vict Sex#12,Vict Descent#13,Premis Cd#14,Premis Desc#15,Weapon Used Cd#16,Weapon Desc#17,Status#18,Status Desc#19,Crm Cd 1#20,Crm Cd 2#21,Crm Cd 3#22,Crm Cd 4#23,... 4 more fields] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DR_NO:int,Date Rptd:string,DATE OCC:string,TIME OCC:int,AREA :int,AREA NAME:string,Rpt Dis...\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26.40231966972351"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_1_Dataframe_API()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7d0ad43-b4f9-4843-ae89-c2f49b003d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+----+\n",
      "|year|month|crime_total|rank|\n",
      "+----+-----+-----------+----+\n",
      "|2010|    3|      17595|   1|\n",
      "|2010|    7|      17520|   2|\n",
      "|2010|    5|      17338|   3|\n",
      "|2011|    8|      17139|   1|\n",
      "|2011|    5|      17050|   2|\n",
      "|2011|    3|      16951|   3|\n",
      "|2012|    8|      17696|   1|\n",
      "|2012|   10|      17477|   2|\n",
      "|2012|    5|      17391|   3|\n",
      "|2013|    8|      17329|   1|\n",
      "|2013|    7|      16714|   2|\n",
      "|2013|    5|      16671|   3|\n",
      "|2014|    7|      14059|   1|\n",
      "|2014|   10|      14031|   2|\n",
      "|2014|    9|      13799|   3|\n",
      "|2015|    8|      18951|   1|\n",
      "|2015|   10|      18916|   2|\n",
      "|2015|    7|      18528|   3|\n",
      "|2016|    8|      19779|   1|\n",
      "|2016|   10|      19615|   2|\n",
      "+----+-----+-----------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [year#1798 ASC NULLS FIRST, rank#1801 ASC NULLS FIRST], true, 0\n",
      "   +- Exchange rangepartitioning(year#1798 ASC NULLS FIRST, rank#1801 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=614]\n",
      "      +- Project [year#1798, month#1799, crime_total#1800L, rank#1801]\n",
      "         +- Filter (rank#1801 <= 3)\n",
      "            +- Window [row_number() windowspecdefinition(_w0#1805, _w1#1806L DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank#1801], [_w0#1805], [_w1#1806L DESC NULLS LAST]\n",
      "               +- WindowGroupLimit [_w0#1805], [_w1#1806L DESC NULLS LAST], row_number(), 3, Final\n",
      "                  +- Sort [_w0#1805 ASC NULLS FIRST, _w1#1806L DESC NULLS LAST], false, 0\n",
      "                     +- Exchange hashpartitioning(_w0#1805, 200), ENSURE_REQUIREMENTS, [plan_id=607]\n",
      "                        +- WindowGroupLimit [_w0#1805], [_w1#1806L DESC NULLS LAST], row_number(), 3, Partial\n",
      "                           +- Sort [_w0#1805 ASC NULLS FIRST, _w1#1806L DESC NULLS LAST], false, 0\n",
      "                              +- HashAggregate(keys=[_groupingexpression#2847, _groupingexpression#2848], functions=[count(1)])\n",
      "                                 +- Exchange hashpartitioning(_groupingexpression#2847, _groupingexpression#2848, 200), ENSURE_REQUIREMENTS, [plan_id=601]\n",
      "                                    +- HashAggregate(keys=[_groupingexpression#2847, _groupingexpression#2848], functions=[partial_count(1)])\n",
      "                                       +- Project [year(cast(Date Rptd#194 as date)) AS _groupingexpression#2847, month(cast(Date Rptd#194 as date)) AS _groupingexpression#2848]\n",
      "                                          +- InMemoryTableScan [Date Rptd#194]\n",
      "                                                +- InMemoryRelation [DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                                                      +- *(1) Project [DR_NO#0, gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS Date Rptd#194, gettimestamp(DATE OCC#2, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#11, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "                                                         +- *(1) ColumnarToRow\n",
      "                                                            +- FileScan parquet [DR_NO#0,Date Rptd#1,DATE OCC#2,TIME OCC#3,AREA #4,AREA NAME#5,Rpt Dist No#6,Part 1-2#7,Crm Cd#8,Crm Cd Desc#9,Mocodes#10,Vict Age#11,Vict Sex#12,Vict Descent#13,Premis Cd#14,Premis Desc#15,Weapon Used Cd#16,Weapon Desc#17,Status#18,Status Desc#19,Crm Cd 1#20,Crm Cd 2#21,Crm Cd 3#22,Crm Cd 4#23,... 4 more fields] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DR_NO:int,Date Rptd:string,DATE OCC:string,TIME OCC:int,AREA :int,AREA NAME:string,Rpt Dis...\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1631157398223877"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_1_SQL_API()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e5649-89cf-4d22-bcca-f0c76f039ddf",
   "metadata": {},
   "source": [
    "# Query 2 on 4 Executors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98250c68-967e-46d6-a097-cf0e07c9b9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|time_group| count|\n",
      "+----------+------+\n",
      "|     Night|237605|\n",
      "| Afternoon|187306|\n",
      "|      Noon|148180|\n",
      "|   Morning|123846|\n",
      "+----------+------+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [count#3056L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(count#3056L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=732]\n",
      "      +- HashAggregate(keys=[time_group#2994], functions=[count(1)])\n",
      "         +- Exchange hashpartitioning(time_group#2994, 200), ENSURE_REQUIREMENTS, [plan_id=729]\n",
      "            +- HashAggregate(keys=[time_group#2994], functions=[partial_count(1)])\n",
      "               +- Project [CASE WHEN ((TIME OCC#3 >= 500) AND (TIME OCC#3 <= 1159)) THEN Morning WHEN ((TIME OCC#3 >= 1200) AND (TIME OCC#3 <= 1659)) THEN Noon WHEN ((TIME OCC#3 >= 1700) AND (TIME OCC#3 <= 2059)) THEN Afternoon ELSE Night END AS time_group#2994]\n",
      "                  +- Filter (isnotnull(Premis_Desc#339) AND (Premis_Desc#339 = STREET))\n",
      "                     +- InMemoryTableScan [Premis_Desc#339, TIME OCC#3], [isnotnull(Premis_Desc#339), (Premis_Desc#339 = STREET)]\n",
      "                           +- InMemoryRelation [DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                                 +- *(1) Project [DR_NO#0, gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS Date Rptd#194, gettimestamp(DATE OCC#2, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#11, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "                                    +- *(1) ColumnarToRow\n",
      "                                       +- FileScan parquet [DR_NO#0,Date Rptd#1,DATE OCC#2,TIME OCC#3,AREA #4,AREA NAME#5,Rpt Dist No#6,Part 1-2#7,Crm Cd#8,Crm Cd Desc#9,Mocodes#10,Vict Age#11,Vict Sex#12,Vict Descent#13,Premis Cd#14,Premis Desc#15,Weapon Used Cd#16,Weapon Desc#17,Status#18,Status Desc#19,Crm Cd 1#20,Crm Cd 2#21,Crm Cd 3#22,Crm Cd 4#23,... 4 more fields] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DR_NO:int,Date Rptd:string,DATE OCC:string,TIME OCC:int,AREA :int,AREA NAME:string,Rpt Dis...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5946252346038818"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_2_Dataframe_API()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05b4d4b6-a5ca-4d86-93c0-72355d45a982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Night: 237605\n",
      "Afternoon: 187306\n",
      "Noon: 148180\n",
      "Morning: 123846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27.94545888900757"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_2_rdd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a199f4e-af1a-4044-aba1-9de3e6dcd2f1",
   "metadata": {},
   "source": [
    "# Query 3 on 4 Executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c4e344e-6eab-480b-b6f8-920f5a78291f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+\n",
      "|Vict Descent|   #|\n",
      "+------------+----+\n",
      "|           H|1556|\n",
      "|           B|1092|\n",
      "|           W|1002|\n",
      "|           O| 484|\n",
      "|           A| 116|\n",
      "|           K|   7|\n",
      "|           J|   3|\n",
      "|           I|   3|\n",
      "|           C|   2|\n",
      "|           F|   1|\n",
      "+------------+----+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [##6037L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(##6037L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=1841]\n",
      "      +- HashAggregate(keys=[Vict Descent#13], functions=[count(1)])\n",
      "         +- Exchange hashpartitioning(Vict Descent#13, 200), ENSURE_REQUIREMENTS, [plan_id=1838]\n",
      "            +- HashAggregate(keys=[Vict Descent#13], functions=[partial_count(1)])\n",
      "               +- Project [Vict Descent#13]\n",
      "                  +- BroadcastHashJoin [Zip Code#4292], [Zip Code#62], Inner, BuildRight, false\n",
      "                     :- Project [Vict Descent#13, cast(ZIPcode#58 as int) AS Zip Code#4292]\n",
      "                     :  +- BroadcastHashJoin [knownfloatingpointnormalized(normalizenanandzero(LAT#281)), knownfloatingpointnormalized(normalizenanandzero(LON#310))], [knownfloatingpointnormalized(normalizenanandzero(LAT#56)), knownfloatingpointnormalized(normalizenanandzero(LON#57))], Inner, BuildRight, false\n",
      "                     :     :- Project [Vict Descent#13, LAT#281, LON#310]\n",
      "                     :     :  +- Filter (((((((isnotnull(Vict Descent#13) AND isnotnull(Vict Sex#12)) AND isnotnull(Date Rptd#194)) AND NOT (Vict Descent#13 = X)) AND NOT (Vict Sex#12 = X)) AND (year(cast(Date Rptd#194 as date)) = 2015)) AND isnotnull(LAT#281)) AND isnotnull(LON#310))\n",
      "                     :     :     +- InMemoryTableScan [Date Rptd#194, LAT#281, LON#310, Vict Descent#13, Vict Sex#12], [isnotnull(Vict Descent#13), isnotnull(Vict Sex#12), isnotnull(Date Rptd#194), NOT (Vict Descent#13 = X), NOT (Vict Sex#12 = X), (year(cast(Date Rptd#194 as date)) = 2015), isnotnull(LAT#281), isnotnull(LON#310)]\n",
      "                     :     :           +- InMemoryRelation [DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                     :     :                 +- *(1) Project [DR_NO#0, gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS Date Rptd#194, gettimestamp(DATE OCC#2, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#11, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "                     :     :                    +- *(1) ColumnarToRow\n",
      "                     :     :                       +- FileScan parquet [DR_NO#0,Date Rptd#1,DATE OCC#2,TIME OCC#3,AREA #4,AREA NAME#5,Rpt Dist No#6,Part 1-2#7,Crm Cd#8,Crm Cd Desc#9,Mocodes#10,Vict Age#11,Vict Sex#12,Vict Descent#13,Premis Cd#14,Premis Desc#15,Weapon Used Cd#16,Weapon Desc#17,Status#18,Status Desc#19,Crm Cd 1#20,Crm Cd 2#21,Crm Cd 3#22,Crm Cd 4#23,... 4 more fields] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DR_NO:int,Date Rptd:string,DATE OCC:string,TIME OCC:int,AREA :int,AREA NAME:string,Rpt Dis...\n",
      "                     :     +- BroadcastExchange HashedRelationBroadcastMode(List(knownfloatingpointnormalized(normalizenanandzero(input[0, double, false])), knownfloatingpointnormalized(normalizenanandzero(input[1, double, false]))),false), [plan_id=1829]\n",
      "                     :        +- Filter (((cast(ZIPcode#58 as int) IN (90021,90058,90013,90272,90077,90274) AND isnotnull(LAT#56)) AND isnotnull(LON#57)) AND isnotnull(cast(ZIPcode#58 as int)))\n",
      "                     :           +- FileScan parquet [LAT#56,LON#57,ZIPcode#58] Batched: true, DataFilters: [cast(ZIPcode#58 as int) IN (90021,90058,90013,90272,90077,90274), isnotnull(LAT#56), isnotnull(L..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/revgecoding.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON)], ReadSchema: struct<LAT:double,LON:double,ZIPcode:string>\n",
      "                     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=1833]\n",
      "                        +- Filter (Zip Code#62 IN (90021,90058,90013,90272,90077,90274) AND isnotnull(Zip Code#62))\n",
      "                           +- FileScan parquet [Zip Code#62] Batched: true, DataFilters: [Zip Code#62 IN (90021,90058,90013,90272,90077,90274), isnotnull(Zip Code#62)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/income/LA_income_2015.parquet], PartitionFilters: [], PushedFilters: [In(`Zip Code`, [90013,90021,90058,90077,90272,90274]), IsNotNull(`Zip Code`)], ReadSchema: struct<Zip Code:int>\n",
      "\n",
      "\n",
      "Method : CONTINUE | Time 11.564699172973633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.564699172973633"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b6323b9-6b57-475f-8595-aaaeb1223108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+\n",
      "|Vict Descent|   #|\n",
      "+------------+----+\n",
      "|           H|1556|\n",
      "|           B|1092|\n",
      "|           W|1002|\n",
      "|           O| 484|\n",
      "|           A| 116|\n",
      "|           K|   7|\n",
      "|           I|   3|\n",
      "|           J|   3|\n",
      "|           C|   2|\n",
      "|           F|   1|\n",
      "+------------+----+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [##726L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(##726L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=1004]\n",
      "      +- HashAggregate(keys=[Vict Descent#13], functions=[count(1)])\n",
      "         +- Exchange hashpartitioning(Vict Descent#13, 200), ENSURE_REQUIREMENTS, [plan_id=1001]\n",
      "            +- HashAggregate(keys=[Vict Descent#13], functions=[partial_count(1)])\n",
      "               +- Project [Vict Descent#13]\n",
      "                  +- BroadcastHashJoin [Zip Code#431], [Zip Code#62], Inner, BuildRight, false\n",
      "                     :- Project [Vict Descent#13, cast(ZIPcode#58 as int) AS Zip Code#431]\n",
      "                     :  +- BroadcastHashJoin [knownfloatingpointnormalized(normalizenanandzero(LAT#26)), knownfloatingpointnormalized(normalizenanandzero(LON#27))], [knownfloatingpointnormalized(normalizenanandzero(LAT#56)), knownfloatingpointnormalized(normalizenanandzero(LON#57))], Inner, BuildRight, false\n",
      "                     :     :- Project [Vict Descent#13, LAT#26, LON#27]\n",
      "                     :     :  +- Filter ((((((isnotnull(Vict Descent#13) AND isnotnull(Vict Sex#12)) AND NOT (Vict Descent#13 = X)) AND NOT (Vict Sex#12 = X)) AND (year(cast(gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) as date)) = 2015)) AND isnotnull(LAT#26)) AND isnotnull(LON#27))\n",
      "                     :     :     +- FileScan parquet [Date Rptd#1,Vict Sex#12,Vict Descent#13,LAT#26,LON#27] Batched: true, DataFilters: [isnotnull(Vict Descent#13), isnotnull(Vict Sex#12), NOT (Vict Descent#13 = X), NOT (Vict Sex#12 ..., Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [IsNotNull(`Vict Descent`), IsNotNull(`Vict Sex`), Not(EqualTo(`Vict Descent`,X)), Not(EqualTo(`V..., ReadSchema: struct<Date Rptd:string,Vict Sex:string,Vict Descent:string,LAT:double,LON:double>\n",
      "                     :     +- BroadcastExchange HashedRelationBroadcastMode(List(knownfloatingpointnormalized(normalizenanandzero(input[0, double, false])), knownfloatingpointnormalized(normalizenanandzero(input[1, double, false]))),false), [plan_id=992]\n",
      "                     :        +- Filter (((cast(ZIPcode#58 as int) IN (90021,90058,90013,90272,90077,90274) AND isnotnull(LAT#56)) AND isnotnull(LON#57)) AND isnotnull(cast(ZIPcode#58 as int)))\n",
      "                     :           +- FileScan parquet [LAT#56,LON#57,ZIPcode#58] Batched: true, DataFilters: [cast(ZIPcode#58 as int) IN (90021,90058,90013,90272,90077,90274), isnotnull(LAT#56), isnotnull(L..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/revgecoding.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON)], ReadSchema: struct<LAT:double,LON:double,ZIPcode:string>\n",
      "                     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=996]\n",
      "                        +- Filter (Zip Code#62 IN (90021,90058,90013,90272,90077,90274) AND isnotnull(Zip Code#62))\n",
      "                           +- FileScan parquet [Zip Code#62] Batched: true, DataFilters: [Zip Code#62 IN (90021,90058,90013,90272,90077,90274), isnotnull(Zip Code#62)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/income/LA_income_2015.parquet], PartitionFilters: [], PushedFilters: [In(`Zip Code`, [90013,90021,90058,90077,90272,90274]), IsNotNull(`Zip Code`)], ReadSchema: struct<Zip Code:int>\n",
      "\n",
      "\n",
      "Method : BROADCAST | Time 11.975245714187622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+\n",
      "|Vict Descent|   #|\n",
      "+------------+----+\n",
      "|           H|1556|\n",
      "|           B|1092|\n",
      "|           W|1002|\n",
      "|           O| 484|\n",
      "|           A| 116|\n",
      "|           K|   7|\n",
      "|           J|   3|\n",
      "|           I|   3|\n",
      "|           C|   2|\n",
      "|           F|   1|\n",
      "+------------+----+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [##1095L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(##1095L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=2379]\n",
      "      +- HashAggregate(keys=[Vict Descent#13], functions=[count(1)])\n",
      "         +- Exchange hashpartitioning(Vict Descent#13, 200), ENSURE_REQUIREMENTS, [plan_id=2376]\n",
      "            +- HashAggregate(keys=[Vict Descent#13], functions=[partial_count(1)])\n",
      "               +- Project [Vict Descent#13]\n",
      "                  +- BroadcastHashJoin [Zip Code#801], [Zip Code#62], Inner, BuildRight, false\n",
      "                     :- Project [Vict Descent#13, cast(ZIPcode#58 as int) AS Zip Code#801]\n",
      "                     :  +- SortMergeJoin [knownfloatingpointnormalized(normalizenanandzero(LAT#26)), knownfloatingpointnormalized(normalizenanandzero(LON#27))], [knownfloatingpointnormalized(normalizenanandzero(LAT#56)), knownfloatingpointnormalized(normalizenanandzero(LON#57))], Inner\n",
      "                     :     :- Sort [knownfloatingpointnormalized(normalizenanandzero(LAT#26)) ASC NULLS FIRST, knownfloatingpointnormalized(normalizenanandzero(LON#27)) ASC NULLS FIRST], false, 0\n",
      "                     :     :  +- Exchange hashpartitioning(knownfloatingpointnormalized(normalizenanandzero(LAT#26)), knownfloatingpointnormalized(normalizenanandzero(LON#27)), 200), ENSURE_REQUIREMENTS, [plan_id=2364]\n",
      "                     :     :     +- Project [Vict Descent#13, LAT#26, LON#27]\n",
      "                     :     :        +- Filter ((((((isnotnull(Vict Descent#13) AND isnotnull(Vict Sex#12)) AND NOT (Vict Descent#13 = X)) AND NOT (Vict Sex#12 = X)) AND (year(cast(gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) as date)) = 2015)) AND isnotnull(LAT#26)) AND isnotnull(LON#27))\n",
      "                     :     :           +- FileScan parquet [Date Rptd#1,Vict Sex#12,Vict Descent#13,LAT#26,LON#27] Batched: true, DataFilters: [isnotnull(Vict Descent#13), isnotnull(Vict Sex#12), NOT (Vict Descent#13 = X), NOT (Vict Sex#12 ..., Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [IsNotNull(`Vict Descent`), IsNotNull(`Vict Sex`), Not(EqualTo(`Vict Descent`,X)), Not(EqualTo(`V..., ReadSchema: struct<Date Rptd:string,Vict Sex:string,Vict Descent:string,LAT:double,LON:double>\n",
      "                     :     +- Sort [knownfloatingpointnormalized(normalizenanandzero(LAT#56)) ASC NULLS FIRST, knownfloatingpointnormalized(normalizenanandzero(LON#57)) ASC NULLS FIRST], false, 0\n",
      "                     :        +- Exchange hashpartitioning(knownfloatingpointnormalized(normalizenanandzero(LAT#56)), knownfloatingpointnormalized(normalizenanandzero(LON#57)), 200), ENSURE_REQUIREMENTS, [plan_id=2365]\n",
      "                     :           +- Filter (((cast(ZIPcode#58 as int) IN (90021,90058,90013,90272,90077,90274) AND isnotnull(LAT#56)) AND isnotnull(LON#57)) AND isnotnull(cast(ZIPcode#58 as int)))\n",
      "                     :              +- FileScan parquet [LAT#56,LON#57,ZIPcode#58] Batched: true, DataFilters: [cast(ZIPcode#58 as int) IN (90021,90058,90013,90272,90077,90274), isnotnull(LAT#56), isnotnull(L..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/revgecoding.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON)], ReadSchema: struct<LAT:double,LON:double,ZIPcode:string>\n",
      "                     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=2371]\n",
      "                        +- Filter (Zip Code#62 IN (90021,90058,90013,90272,90077,90274) AND isnotnull(Zip Code#62))\n",
      "                           +- FileScan parquet [Zip Code#62] Batched: true, DataFilters: [Zip Code#62 IN (90021,90058,90013,90272,90077,90274), isnotnull(Zip Code#62)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/income/LA_income_2015.parquet], PartitionFilters: [], PushedFilters: [In(`Zip Code`, [90013,90021,90058,90077,90272,90274]), IsNotNull(`Zip Code`)], ReadSchema: struct<Zip Code:int>\n",
      "\n",
      "\n",
      "Method : MERGE | Time 11.433407068252563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+\n",
      "|Vict Descent|   #|\n",
      "+------------+----+\n",
      "|           H|1556|\n",
      "|           B|1092|\n",
      "|           W|1002|\n",
      "|           O| 484|\n",
      "|           A| 116|\n",
      "|           K|   7|\n",
      "|           J|   3|\n",
      "|           I|   3|\n",
      "|           C|   2|\n",
      "|           F|   1|\n",
      "+------------+----+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [##1464L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(##1464L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=3426]\n",
      "      +- HashAggregate(keys=[Vict Descent#13], functions=[count(1)])\n",
      "         +- Exchange hashpartitioning(Vict Descent#13, 200), ENSURE_REQUIREMENTS, [plan_id=3423]\n",
      "            +- HashAggregate(keys=[Vict Descent#13], functions=[partial_count(1)])\n",
      "               +- Project [Vict Descent#13]\n",
      "                  +- BroadcastHashJoin [Zip Code#1170], [Zip Code#62], Inner, BuildRight, false\n",
      "                     :- Project [Vict Descent#13, cast(ZIPcode#58 as int) AS Zip Code#1170]\n",
      "                     :  +- ShuffledHashJoin [knownfloatingpointnormalized(normalizenanandzero(LAT#26)), knownfloatingpointnormalized(normalizenanandzero(LON#27))], [knownfloatingpointnormalized(normalizenanandzero(LAT#56)), knownfloatingpointnormalized(normalizenanandzero(LON#57))], Inner, BuildLeft\n",
      "                     :     :- Exchange hashpartitioning(knownfloatingpointnormalized(normalizenanandzero(LAT#26)), knownfloatingpointnormalized(normalizenanandzero(LON#27)), 200), ENSURE_REQUIREMENTS, [plan_id=3413]\n",
      "                     :     :  +- Project [Vict Descent#13, LAT#26, LON#27]\n",
      "                     :     :     +- Filter ((((((isnotnull(Vict Descent#13) AND isnotnull(Vict Sex#12)) AND NOT (Vict Descent#13 = X)) AND NOT (Vict Sex#12 = X)) AND (year(cast(gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) as date)) = 2015)) AND isnotnull(LAT#26)) AND isnotnull(LON#27))\n",
      "                     :     :        +- FileScan parquet [Date Rptd#1,Vict Sex#12,Vict Descent#13,LAT#26,LON#27] Batched: true, DataFilters: [isnotnull(Vict Descent#13), isnotnull(Vict Sex#12), NOT (Vict Descent#13 = X), NOT (Vict Sex#12 ..., Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [IsNotNull(`Vict Descent`), IsNotNull(`Vict Sex`), Not(EqualTo(`Vict Descent`,X)), Not(EqualTo(`V..., ReadSchema: struct<Date Rptd:string,Vict Sex:string,Vict Descent:string,LAT:double,LON:double>\n",
      "                     :     +- Exchange hashpartitioning(knownfloatingpointnormalized(normalizenanandzero(LAT#56)), knownfloatingpointnormalized(normalizenanandzero(LON#57)), 200), ENSURE_REQUIREMENTS, [plan_id=3414]\n",
      "                     :        +- Filter (((cast(ZIPcode#58 as int) IN (90021,90058,90013,90272,90077,90274) AND isnotnull(LAT#56)) AND isnotnull(LON#57)) AND isnotnull(cast(ZIPcode#58 as int)))\n",
      "                     :           +- FileScan parquet [LAT#56,LON#57,ZIPcode#58] Batched: true, DataFilters: [cast(ZIPcode#58 as int) IN (90021,90058,90013,90272,90077,90274), isnotnull(LAT#56), isnotnull(L..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/revgecoding.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON)], ReadSchema: struct<LAT:double,LON:double,ZIPcode:string>\n",
      "                     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=3418]\n",
      "                        +- Filter (Zip Code#62 IN (90021,90058,90013,90272,90077,90274) AND isnotnull(Zip Code#62))\n",
      "                           +- FileScan parquet [Zip Code#62] Batched: true, DataFilters: [Zip Code#62 IN (90021,90058,90013,90272,90077,90274), isnotnull(Zip Code#62)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/income/LA_income_2015.parquet], PartitionFilters: [], PushedFilters: [In(`Zip Code`, [90013,90021,90058,90077,90272,90274]), IsNotNull(`Zip Code`)], ReadSchema: struct<Zip Code:int>\n",
      "\n",
      "\n",
      "Method : SHUFFLE_HASH | Time 9.664622783660889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.                 (0 + 0) / 6]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBROADCAST\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMERGE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSHUFFLE_HASH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSHUFFLE_REPLICATE_NL\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mquery_3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 54\u001b[0m, in \u001b[0;36mquery_3\u001b[0;34m(method)\u001b[0m\n\u001b[1;32m     46\u001b[0m min_income_zip_codes \u001b[38;5;241m=\u001b[39m crime_data_join_income\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZip Code\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m     47\u001b[0m                         \u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstimated Median Income\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m}) \\\n\u001b[1;32m     48\u001b[0m                         \u001b[38;5;241m.\u001b[39mwithColumnRenamed(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin(Estimated Median Income)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinIncome\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m     49\u001b[0m                         \u001b[38;5;241m.\u001b[39morderBy(col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinIncome\u001b[39m\u001b[38;5;124m'\u001b[39m)) \\\n\u001b[1;32m     50\u001b[0m                         \u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     52\u001b[0m zip_codes \u001b[38;5;241m=\u001b[39m min_income_zip_codes\u001b[38;5;241m.\u001b[39munion(max_income_zip_codes)\n\u001b[0;32m---> 54\u001b[0m zip_codes_list \u001b[38;5;241m=\u001b[39m [row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZip Code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mzip_codes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     56\u001b[0m result \u001b[38;5;241m=\u001b[39m crime_data_join_income \\\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;241m.\u001b[39mfilter(col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZip Code\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39misin(zip_codes_list)) \\\n\u001b[1;32m     58\u001b[0m             \u001b[38;5;241m.\u001b[39mfilter(year(col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate Rptd\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2015\u001b[39m) \\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[38;5;241m.\u001b[39mwithColumnRenamed(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m     62\u001b[0m             \u001b[38;5;241m.\u001b[39morderBy(col(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdesc())\n\u001b[1;32m     64\u001b[0m result\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/opt/spark/python/pyspark/sql/dataframe.py:1257\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m   1238\u001b[0m \n\u001b[1;32m   1239\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[0;32m-> 1257\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:>                 (0 + 4) / 6][Stage 70:>                 (0 + 0) / 6]\r"
     ]
    }
   ],
   "source": [
    "for method in ['BROADCAST','MERGE', 'SHUFFLE_HASH', 'SHUFFLE_REPLICATE_NL']:\n",
    "    query_3(method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cfaa40-3215-4fb1-9c20-d6e1831c26ba",
   "metadata": {},
   "source": [
    "# Query 4 on 4 Executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b56f3227-7e31-41ce-9fe2-3ad13c94bdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 110:===============================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+----+\n",
      "|year|  average_distance|   #|\n",
      "+----+------------------+----+\n",
      "|2010|4.3255933001101114|8162|\n",
      "|2011|2.7909872168227423|7225|\n",
      "|2012| 37.45827620685533|6539|\n",
      "|2013| 2.830553808457538|5851|\n",
      "|2014|11.043993584711998|4559|\n",
      "|2015| 2.706546019966876|6729|\n",
      "|2016| 2.718165310899851|8094|\n",
      "|2017|4.3382539597541765|7781|\n",
      "|2018|2.7360981635514983|7414|\n",
      "|2019| 2.741344160752832|7135|\n",
      "|2020|2.3272432584812806|  46|\n",
      "|2021|37.382419651864836|2553|\n",
      "|2022|2.9681689538445584|  44|\n",
      "|2023| 3.687948331136995|   8|\n",
      "+----+------------------+----+\n",
      "\n",
      "Method : CONTINUE | Time 5.425380706787109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.425380706787109"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_4_1a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb4c2627-39c0-4a25-aedc-b45189117425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 114:============================>                            (3 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-----+\n",
      "|   division|  average_distance|    #|\n",
      "+-----------+------------------+-----+\n",
      "|77th Street| 6.913894657106163|68326|\n",
      "|  Southeast|12.025486164617545|57011|\n",
      "|  Southwest| 6.551382718135036|54271|\n",
      "|     Newton|5.2361202832288685|43355|\n",
      "|    Central| 3.166545740156361|40488|\n",
      "|    Rampart| 7.047477633659231|38908|\n",
      "|    Olympic|16.976357519281617|37199|\n",
      "|  Hollywood| 6.751386163782782|32995|\n",
      "|    Mission|20.666096061806797|32334|\n",
      "| Hollenbeck|12.702801855459152|29901|\n",
      "|    Pacific|12.047038740457603|29074|\n",
      "|N Hollywood|12.204292484887183|28702|\n",
      "|     Harbor| 7.460827048756396|28540|\n",
      "|   Foothill|14.305736282276778|27415|\n",
      "|  Northeast| 9.093017340351224|27230|\n",
      "|   Wilshire| 7.054111333900138|26772|\n",
      "|   Van Nuys|  8.87387830707935|26089|\n",
      "|    Topanga| 8.057323863764594|24822|\n",
      "| Devonshire|13.826966000368188|23013|\n",
      "|West Valley|10.031539994619983|22791|\n",
      "+-----------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Method : CONTINUE | Time 2.4252140522003174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.4252140522003174"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_4_1b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77fccae6-016c-4a45-8a07-888ea44ae9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 123:==========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+-----+\n",
      "|year|  average_distance|    #|\n",
      "+----+------------------+-----+\n",
      "|2010|3.9757578208226914| 8162|\n",
      "|2011|2.4590852830727155| 7225|\n",
      "|2012| 37.10529402034977| 6539|\n",
      "|2013| 2.459919591596096| 5851|\n",
      "|2014|10.659354948051488| 4559|\n",
      "|2015|2.3889866668876283| 6729|\n",
      "|2016|2.4268077758998485| 8094|\n",
      "|2017| 4.006458967994438| 7781|\n",
      "|2018|2.4123576588935918| 7414|\n",
      "|2019|2.4311257325392552| 7135|\n",
      "|2020| 8.300434266099332| 8496|\n",
      "|2021|  32.0668887686691|17410|\n",
      "|2022|2.3181733400905924|10139|\n",
      "|2023|2.2683855904462207| 8955|\n",
      "+----+------------------+-----+\n",
      "\n",
      "Method : CONTINUE | Time 95.02895522117615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.02895522117615"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_4_2a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2029fb8d-319d-4e31-a8e6-69b97c06722e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 132:============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-----+\n",
      "|   division|  average_distance|    #|\n",
      "+-----------+------------------+-----+\n",
      "|77th Street|12.567122296795125|94853|\n",
      "|  Southeast|25.601298738797524|87905|\n",
      "|  Southwest| 9.329186662576602|72814|\n",
      "|    Central|23.269811961478677|63606|\n",
      "|     Newton|13.433184721292792|61408|\n",
      "|    Olympic|   36.348197450529|60925|\n",
      "|    Rampart|19.629568008429306|55881|\n",
      "|  Hollywood|27.671748021149348|51255|\n",
      "|    Mission| 34.80052558861396|48956|\n",
      "|    Pacific|24.825461959674055|43019|\n",
      "|   Foothill|29.797575113580432|41625|\n",
      "| Hollenbeck| 19.52127635437576|41540|\n",
      "|N Hollywood| 17.69148313156268|41151|\n",
      "|     Harbor|13.982027989409763|40854|\n",
      "|    Topanga| 6.096105827278324|39337|\n",
      "|   Wilshire|15.736618712905988|37930|\n",
      "|  Northeast|12.367411075059353|37334|\n",
      "| Devonshire|23.046036251700617|36902|\n",
      "|   Van Nuys|19.788057065178123|36264|\n",
      "|West Valley| 14.71804024306935|34005|\n",
      "+-----------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Method : CONTINUE | Time 92.97774457931519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92.97774457931519"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_4_2b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2a9b5b2-94ae-4cb5-80d2-cb8f8775152b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [AREA#22943, DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 10 more fields]\n",
      "   +- BroadcastHashJoin [AREA#22943], [AREA#22936], Inner, BuildRight, false\n",
      "      :- Project [DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA #4 AS AREA#22943, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "      :  +- Filter isnotnull(AREA #4)\n",
      "      :     +- InMemoryTableScan [AREA #4, AREA NAME#5, Crm Cd#8, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, Crm Cd Desc#9, Cross Street#25, DATE OCC#223, DR_NO#0, Date Rptd#194, LAT#281, LOCATION#24, LON#310, Mocodes#10, Part 1-2#7, Premis Cd#14, Premis Desc#15, Premis_Desc#339, Rpt Dist No#6, Status#18, Status Desc#19, TIME OCC#3, ... 5 more fields], [isnotnull(AREA #4)]\n",
      "      :           +- InMemoryRelation [DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "      :                 +- *(1) Project [DR_NO#0, gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS Date Rptd#194, gettimestamp(DATE OCC#2, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#11, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "      :                    +- *(1) ColumnarToRow\n",
      "      :                       +- FileScan parquet [DR_NO#0,Date Rptd#1,DATE OCC#2,TIME OCC#3,AREA #4,AREA NAME#5,Rpt Dist No#6,Part 1-2#7,Crm Cd#8,Crm Cd Desc#9,Mocodes#10,Vict Age#11,Vict Sex#12,Vict Descent#13,Premis Cd#14,Premis Desc#15,Weapon Used Cd#16,Weapon Desc#17,Status#18,Status Desc#19,Crm Cd 1#20,Crm Cd 2#21,Crm Cd 3#22,Crm Cd 4#23,... 4 more fields] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DR_NO:int,Date Rptd:string,DATE OCC:string,TIME OCC:int,AREA :int,AREA NAME:string,Rpt Dis...\n",
      "      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[5, int, true] as bigint)),false), [plan_id=7459]\n",
      "         +- Project [X#68, Y#69, FID#70, DIVISION#71, LOCATION#72, PREC#73 AS AREA#22936]\n",
      "            +- Filter isnotnull(PREC#73)\n",
      "               +- FileScan parquet [X#68,Y#69,FID#70,DIVISION#71,LOCATION#72,PREC#73] Batched: true, DataFilters: [isnotnull(PREC#73)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/LAPD_Police_Stations.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(PREC)], ReadSchema: struct<X:double,Y:double,FID:int,DIVISION:string,LOCATION:string,PREC:int>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+----+\n",
      "|year|  average_distance|   #|\n",
      "+----+------------------+----+\n",
      "|2010|4.3255933001101114|8162|\n",
      "|2011|2.7909872168227423|7225|\n",
      "|2012| 37.45827620685533|6539|\n",
      "|2013| 2.830553808457538|5851|\n",
      "|2014|11.043993584711998|4559|\n",
      "|2015| 2.706546019966876|6729|\n",
      "|2016| 2.718165310899851|8094|\n",
      "|2017|4.3382539597541765|7781|\n",
      "|2018|2.7360981635514983|7414|\n",
      "|2019| 2.741344160752832|7135|\n",
      "|2020|2.3272432584812806|  46|\n",
      "|2021|37.382419651864836|2553|\n",
      "|2022|2.9681689538445584|  44|\n",
      "|2023| 3.687948331136995|   8|\n",
      "+----+------------------+----+\n",
      "\n",
      "Method : BROADCAST | Time 1.3421380519866943\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [AREA#24349, DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 10 more fields]\n",
      "   +- SortMergeJoin [AREA#24349], [AREA#24342], Inner\n",
      "      :- Sort [AREA#24349 ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(AREA#24349, 200), ENSURE_REQUIREMENTS, [plan_id=7714]\n",
      "      :     +- Project [DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA #4 AS AREA#24349, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "      :        +- Filter isnotnull(AREA #4)\n",
      "      :           +- InMemoryTableScan [AREA #4, AREA NAME#5, Crm Cd#8, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, Crm Cd Desc#9, Cross Street#25, DATE OCC#223, DR_NO#0, Date Rptd#194, LAT#281, LOCATION#24, LON#310, Mocodes#10, Part 1-2#7, Premis Cd#14, Premis Desc#15, Premis_Desc#339, Rpt Dist No#6, Status#18, Status Desc#19, TIME OCC#3, ... 5 more fields], [isnotnull(AREA #4)]\n",
      "      :                 +- InMemoryRelation [DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "      :                       +- *(1) Project [DR_NO#0, gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS Date Rptd#194, gettimestamp(DATE OCC#2, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#11, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "      :                          +- *(1) ColumnarToRow\n",
      "      :                             +- FileScan parquet [DR_NO#0,Date Rptd#1,DATE OCC#2,TIME OCC#3,AREA #4,AREA NAME#5,Rpt Dist No#6,Part 1-2#7,Crm Cd#8,Crm Cd Desc#9,Mocodes#10,Vict Age#11,Vict Sex#12,Vict Descent#13,Premis Cd#14,Premis Desc#15,Weapon Used Cd#16,Weapon Desc#17,Status#18,Status Desc#19,Crm Cd 1#20,Crm Cd 2#21,Crm Cd 3#22,Crm Cd 4#23,... 4 more fields] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DR_NO:int,Date Rptd:string,DATE OCC:string,TIME OCC:int,AREA :int,AREA NAME:string,Rpt Dis...\n",
      "      +- Sort [AREA#24342 ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(AREA#24342, 200), ENSURE_REQUIREMENTS, [plan_id=7715]\n",
      "            +- Project [X#68, Y#69, FID#70, DIVISION#71, LOCATION#72, PREC#73 AS AREA#24342]\n",
      "               +- Filter isnotnull(PREC#73)\n",
      "                  +- FileScan parquet [X#68,Y#69,FID#70,DIVISION#71,LOCATION#72,PREC#73] Batched: true, DataFilters: [isnotnull(PREC#73)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/LAPD_Police_Stations.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(PREC)], ReadSchema: struct<X:double,Y:double,FID:int,DIVISION:string,LOCATION:string,PREC:int>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+----+\n",
      "|year|  average_distance|   #|\n",
      "+----+------------------+----+\n",
      "|2010| 4.325593300110116|8162|\n",
      "|2011|2.7909872168227494|7225|\n",
      "|2012| 37.45827620685538|6539|\n",
      "|2013| 2.830553808457538|5851|\n",
      "|2014|11.043993584711966|4559|\n",
      "|2015|2.7065460199668823|6729|\n",
      "|2016| 2.718165310899849|8094|\n",
      "|2017| 4.338253959754184|7781|\n",
      "|2018|2.7360981635515005|7414|\n",
      "|2019|2.7413441607528366|7135|\n",
      "|2020|  2.32724325848128|  46|\n",
      "|2021| 37.38241965186492|2553|\n",
      "|2022|2.9681689538445593|  44|\n",
      "|2023|3.6879483311369956|   8|\n",
      "+----+------------------+----+\n",
      "\n",
      "Method : MERGE | Time 1.4247801303863525\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [AREA#25756, DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 10 more fields]\n",
      "   +- ShuffledHashJoin [AREA#25756], [AREA#25749], Inner, BuildLeft\n",
      "      :- Exchange hashpartitioning(AREA#25756, 200), ENSURE_REQUIREMENTS, [plan_id=8110]\n",
      "      :  +- Project [DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA #4 AS AREA#25756, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "      :     +- Filter isnotnull(AREA #4)\n",
      "      :        +- InMemoryTableScan [AREA #4, AREA NAME#5, Crm Cd#8, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, Crm Cd Desc#9, Cross Street#25, DATE OCC#223, DR_NO#0, Date Rptd#194, LAT#281, LOCATION#24, LON#310, Mocodes#10, Part 1-2#7, Premis Cd#14, Premis Desc#15, Premis_Desc#339, Rpt Dist No#6, Status#18, Status Desc#19, TIME OCC#3, ... 5 more fields], [isnotnull(AREA #4)]\n",
      "      :              +- InMemoryRelation [DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "      :                    +- *(1) Project [DR_NO#0, gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS Date Rptd#194, gettimestamp(DATE OCC#2, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#11, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "      :                       +- *(1) ColumnarToRow\n",
      "      :                          +- FileScan parquet [DR_NO#0,Date Rptd#1,DATE OCC#2,TIME OCC#3,AREA #4,AREA NAME#5,Rpt Dist No#6,Part 1-2#7,Crm Cd#8,Crm Cd Desc#9,Mocodes#10,Vict Age#11,Vict Sex#12,Vict Descent#13,Premis Cd#14,Premis Desc#15,Weapon Used Cd#16,Weapon Desc#17,Status#18,Status Desc#19,Crm Cd 1#20,Crm Cd 2#21,Crm Cd 3#22,Crm Cd 4#23,... 4 more fields] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DR_NO:int,Date Rptd:string,DATE OCC:string,TIME OCC:int,AREA :int,AREA NAME:string,Rpt Dis...\n",
      "      +- Exchange hashpartitioning(AREA#25749, 200), ENSURE_REQUIREMENTS, [plan_id=8111]\n",
      "         +- Project [X#68, Y#69, FID#70, DIVISION#71, LOCATION#72, PREC#73 AS AREA#25749]\n",
      "            +- Filter isnotnull(PREC#73)\n",
      "               +- FileScan parquet [X#68,Y#69,FID#70,DIVISION#71,LOCATION#72,PREC#73] Batched: true, DataFilters: [isnotnull(PREC#73)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/LAPD_Police_Stations.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(PREC)], ReadSchema: struct<X:double,Y:double,FID:int,DIVISION:string,LOCATION:string,PREC:int>\n",
      "\n",
      "\n",
      "+----+------------------+----+\n",
      "|year|  average_distance|   #|\n",
      "+----+------------------+----+\n",
      "|2010| 4.325593300110093|8162|\n",
      "|2011|2.7909872168227383|7225|\n",
      "|2012| 37.45827620685534|6539|\n",
      "|2013|2.8305538084575415|5851|\n",
      "|2014|11.043993584712029|4559|\n",
      "|2015|2.7065460199668934|6729|\n",
      "|2016| 2.718165310899838|8094|\n",
      "|2017| 4.338253959754198|7781|\n",
      "|2018|2.7360981635514983|7414|\n",
      "|2019| 2.741344160752827|7135|\n",
      "|2020|2.3272432584812806|  46|\n",
      "|2021| 37.38241965186492|2553|\n",
      "|2022|2.9681689538445584|  44|\n",
      "|2023|3.6879483311369956|   8|\n",
      "+----+------------------+----+\n",
      "\n",
      "Method : SHUFFLE_HASH | Time 1.2632167339324951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for method in ['BROADCAST','MERGE', 'SHUFFLE_HASH']:\n",
    "    query_4_1a(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62ffad6f-3f43-4660-98ff-44ff85fd42c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [AREA#27163, DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 10 more fields]\n",
      "   +- BroadcastHashJoin [AREA#27163], [AREA#27156], Inner, BuildRight, false\n",
      "      :- Project [DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA #4 AS AREA#27163, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "      :  +- Filter isnotnull(AREA #4)\n",
      "      :     +- InMemoryTableScan [AREA #4, AREA NAME#5, Crm Cd#8, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, Crm Cd Desc#9, Cross Street#25, DATE OCC#223, DR_NO#0, Date Rptd#194, LAT#281, LOCATION#24, LON#310, Mocodes#10, Part 1-2#7, Premis Cd#14, Premis Desc#15, Premis_Desc#339, Rpt Dist No#6, Status#18, Status Desc#19, TIME OCC#3, ... 5 more fields], [isnotnull(AREA #4)]\n",
      "      :           +- InMemoryRelation [DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "      :                 +- *(1) Project [DR_NO#0, gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS Date Rptd#194, gettimestamp(DATE OCC#2, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#11, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "      :                    +- *(1) ColumnarToRow\n",
      "      :                       +- FileScan parquet [DR_NO#0,Date Rptd#1,DATE OCC#2,TIME OCC#3,AREA #4,AREA NAME#5,Rpt Dist No#6,Part 1-2#7,Crm Cd#8,Crm Cd Desc#9,Mocodes#10,Vict Age#11,Vict Sex#12,Vict Descent#13,Premis Cd#14,Premis Desc#15,Weapon Used Cd#16,Weapon Desc#17,Status#18,Status Desc#19,Crm Cd 1#20,Crm Cd 2#21,Crm Cd 3#22,Crm Cd 4#23,... 4 more fields] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DR_NO:int,Date Rptd:string,DATE OCC:string,TIME OCC:int,AREA :int,AREA NAME:string,Rpt Dis...\n",
      "      +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[5, int, true] as bigint)),false), [plan_id=8454]\n",
      "         +- Project [X#68, Y#69, FID#70, DIVISION#71, LOCATION#72, PREC#73 AS AREA#27156]\n",
      "            +- Filter isnotnull(PREC#73)\n",
      "               +- FileScan parquet [X#68,Y#69,FID#70,DIVISION#71,LOCATION#72,PREC#73] Batched: true, DataFilters: [isnotnull(PREC#73)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/LAPD_Police_Stations.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(PREC)], ReadSchema: struct<X:double,Y:double,FID:int,DIVISION:string,LOCATION:string,PREC:int>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-----+\n",
      "|   division|  average_distance|    #|\n",
      "+-----------+------------------+-----+\n",
      "|77th Street| 6.913894657106162|68326|\n",
      "|  Southeast|12.025486164617545|57011|\n",
      "|  Southwest| 6.551382718135037|54271|\n",
      "|     Newton| 5.236120283228869|43355|\n",
      "|    Central|3.1665457401563613|40488|\n",
      "|    Rampart| 7.047477633659229|38908|\n",
      "|    Olympic| 16.97635751928162|37199|\n",
      "|  Hollywood| 6.751386163782781|32995|\n",
      "|    Mission|20.666096061806797|32334|\n",
      "| Hollenbeck| 12.70280185545915|29901|\n",
      "|    Pacific|12.047038740457603|29074|\n",
      "|N Hollywood|12.204292484887182|28702|\n",
      "|     Harbor| 7.460827048756397|28540|\n",
      "|   Foothill|14.305736282276778|27415|\n",
      "|  Northeast| 9.093017340351224|27230|\n",
      "|   Wilshire| 7.054111333900138|26772|\n",
      "|   Van Nuys|  8.87387830707935|26089|\n",
      "|    Topanga| 8.057323863764594|24822|\n",
      "| Devonshire|13.826966000368186|23013|\n",
      "|West Valley|10.031539994619987|22791|\n",
      "+-----------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Method : BROADCAST | Time 1.9325966835021973\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [AREA#28573, DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 10 more fields]\n",
      "   +- SortMergeJoin [AREA#28573], [AREA#28566], Inner\n",
      "      :- Sort [AREA#28573 ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(AREA#28573, 200), ENSURE_REQUIREMENTS, [plan_id=8709]\n",
      "      :     +- Project [DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA #4 AS AREA#28573, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "      :        +- Filter isnotnull(AREA #4)\n",
      "      :           +- InMemoryTableScan [AREA #4, AREA NAME#5, Crm Cd#8, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, Crm Cd Desc#9, Cross Street#25, DATE OCC#223, DR_NO#0, Date Rptd#194, LAT#281, LOCATION#24, LON#310, Mocodes#10, Part 1-2#7, Premis Cd#14, Premis Desc#15, Premis_Desc#339, Rpt Dist No#6, Status#18, Status Desc#19, TIME OCC#3, ... 5 more fields], [isnotnull(AREA #4)]\n",
      "      :                 +- InMemoryRelation [DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "      :                       +- *(1) Project [DR_NO#0, gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS Date Rptd#194, gettimestamp(DATE OCC#2, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#11, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "      :                          +- *(1) ColumnarToRow\n",
      "      :                             +- FileScan parquet [DR_NO#0,Date Rptd#1,DATE OCC#2,TIME OCC#3,AREA #4,AREA NAME#5,Rpt Dist No#6,Part 1-2#7,Crm Cd#8,Crm Cd Desc#9,Mocodes#10,Vict Age#11,Vict Sex#12,Vict Descent#13,Premis Cd#14,Premis Desc#15,Weapon Used Cd#16,Weapon Desc#17,Status#18,Status Desc#19,Crm Cd 1#20,Crm Cd 2#21,Crm Cd 3#22,Crm Cd 4#23,... 4 more fields] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DR_NO:int,Date Rptd:string,DATE OCC:string,TIME OCC:int,AREA :int,AREA NAME:string,Rpt Dis...\n",
      "      +- Sort [AREA#28566 ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(AREA#28566, 200), ENSURE_REQUIREMENTS, [plan_id=8710]\n",
      "            +- Project [X#68, Y#69, FID#70, DIVISION#71, LOCATION#72, PREC#73 AS AREA#28566]\n",
      "               +- Filter isnotnull(PREC#73)\n",
      "                  +- FileScan parquet [X#68,Y#69,FID#70,DIVISION#71,LOCATION#72,PREC#73] Batched: true, DataFilters: [isnotnull(PREC#73)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/LAPD_Police_Stations.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(PREC)], ReadSchema: struct<X:double,Y:double,FID:int,DIVISION:string,LOCATION:string,PREC:int>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-----+\n",
      "|   division|  average_distance|    #|\n",
      "+-----------+------------------+-----+\n",
      "|77th Street| 6.913894657106623|68326|\n",
      "|  Southeast|12.025486164617854|57011|\n",
      "|  Southwest| 6.551382718135446|54271|\n",
      "|     Newton| 5.236120283228738|43355|\n",
      "|    Central|3.1665457401567365|40488|\n",
      "|    Rampart| 7.047477633659364|38908|\n",
      "|    Olympic| 16.97635751928094|37199|\n",
      "|  Hollywood| 6.751386163783306|32995|\n",
      "|    Mission|20.666096061806485|32334|\n",
      "| Hollenbeck| 12.70280185545926|29901|\n",
      "|    Pacific|12.047038740456975|29074|\n",
      "|N Hollywood|12.204292484887173|28702|\n",
      "|     Harbor| 7.460827048756571|28540|\n",
      "|   Foothill|14.305736282276577|27415|\n",
      "|  Northeast| 9.093017340351318|27230|\n",
      "|   Wilshire| 7.054111333900119|26772|\n",
      "|   Van Nuys|  8.87387830707965|26089|\n",
      "|    Topanga| 8.057323863764802|24822|\n",
      "| Devonshire|13.826966000368254|23013|\n",
      "|West Valley|10.031539994619937|22791|\n",
      "+-----------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Method : MERGE | Time 2.5821611881256104\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Project [AREA#29984, DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 10 more fields]\n",
      "   +- ShuffledHashJoin [AREA#29984], [AREA#29977], Inner, BuildLeft\n",
      "      :- Exchange hashpartitioning(AREA#29984, 200), ENSURE_REQUIREMENTS, [plan_id=9105]\n",
      "      :  +- Project [DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA #4 AS AREA#29984, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "      :     +- Filter isnotnull(AREA #4)\n",
      "      :        +- InMemoryTableScan [AREA #4, AREA NAME#5, Crm Cd#8, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, Crm Cd Desc#9, Cross Street#25, DATE OCC#223, DR_NO#0, Date Rptd#194, LAT#281, LOCATION#24, LON#310, Mocodes#10, Part 1-2#7, Premis Cd#14, Premis Desc#15, Premis_Desc#339, Rpt Dist No#6, Status#18, Status Desc#19, TIME OCC#3, ... 5 more fields], [isnotnull(AREA #4)]\n",
      "      :              +- InMemoryRelation [DR_NO#0, Date Rptd#194, DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#252, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "      :                    +- *(1) Project [DR_NO#0, gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS Date Rptd#194, gettimestamp(DATE OCC#2, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS DATE OCC#223, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#11, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "      :                       +- *(1) ColumnarToRow\n",
      "      :                          +- FileScan parquet [DR_NO#0,Date Rptd#1,DATE OCC#2,TIME OCC#3,AREA #4,AREA NAME#5,Rpt Dist No#6,Part 1-2#7,Crm Cd#8,Crm Cd Desc#9,Mocodes#10,Vict Age#11,Vict Sex#12,Vict Descent#13,Premis Cd#14,Premis Desc#15,Weapon Used Cd#16,Weapon Desc#17,Status#18,Status Desc#19,Crm Cd 1#20,Crm Cd 2#21,Crm Cd 3#22,Crm Cd 4#23,... 4 more fields] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DR_NO:int,Date Rptd:string,DATE OCC:string,TIME OCC:int,AREA :int,AREA NAME:string,Rpt Dis...\n",
      "      +- Exchange hashpartitioning(AREA#29977, 200), ENSURE_REQUIREMENTS, [plan_id=9106]\n",
      "         +- Project [X#68, Y#69, FID#70, DIVISION#71, LOCATION#72, PREC#73 AS AREA#29977]\n",
      "            +- Filter isnotnull(PREC#73)\n",
      "               +- FileScan parquet [X#68,Y#69,FID#70,DIVISION#71,LOCATION#72,PREC#73] Batched: true, DataFilters: [isnotnull(PREC#73)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/LAPD_Police_Stations.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(PREC)], ReadSchema: struct<X:double,Y:double,FID:int,DIVISION:string,LOCATION:string,PREC:int>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 176:=============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-----+\n",
      "|   division|  average_distance|    #|\n",
      "+-----------+------------------+-----+\n",
      "|77th Street| 6.913894657106429|68326|\n",
      "|  Southeast|12.025486164617966|57011|\n",
      "|  Southwest| 6.551382718135404|54271|\n",
      "|     Newton| 5.236120283228695|43355|\n",
      "|    Central| 3.166545740156838|40488|\n",
      "|    Rampart|7.0474776336593425|38908|\n",
      "|    Olympic|  16.9763575192807|37199|\n",
      "|  Hollywood| 6.751386163783392|32995|\n",
      "|    Mission|20.666096061805494|32334|\n",
      "| Hollenbeck|12.702801855459127|29901|\n",
      "|    Pacific|12.047038740457138|29074|\n",
      "|N Hollywood|12.204292484887345|28702|\n",
      "|     Harbor| 7.460827048756491|28540|\n",
      "|   Foothill|14.305736282276635|27415|\n",
      "|  Northeast|  9.09301734035126|27230|\n",
      "|   Wilshire| 7.054111333900124|26772|\n",
      "|   Van Nuys| 8.873878307079364|26089|\n",
      "|    Topanga| 8.057323863764784|24822|\n",
      "| Devonshire|13.826966000368301|23013|\n",
      "|West Valley|10.031539994620017|22791|\n",
      "+-----------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Method : SHUFFLE_HASH | Time 3.875988721847534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for method in ['BROADCAST','MERGE', 'SHUFFLE_HASH']:\n",
    "    query_4_1b(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15089bd1-65f3-47b0-a2ae-1b1e5030aad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/12 15:49:35 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- BroadcastNestedLoopJoin BuildRight, Cross\n",
      "   :- Project [DR_NO#0, gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS Date Rptd#80, gettimestamp(DATE OCC#2, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS DATE OCC#110, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#11, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "   :  +- FileScan parquet [DR_NO#0,Date Rptd#1,DATE OCC#2,TIME OCC#3,AREA #4,AREA NAME#5,Rpt Dist No#6,Part 1-2#7,Crm Cd#8,Crm Cd Desc#9,Mocodes#10,Vict Age#11,Vict Sex#12,Vict Descent#13,Premis Cd#14,Premis Desc#15,Weapon Used Cd#16,Weapon Desc#17,Status#18,Status Desc#19,Crm Cd 1#20,Crm Cd 2#21,Crm Cd 3#22,Crm Cd 4#23,... 4 more fields] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DR_NO:int,Date Rptd:string,DATE OCC:string,TIME OCC:int,AREA :int,AREA NAME:string,Rpt Dis...\n",
      "   +- BroadcastExchange IdentityBroadcastMode, [plan_id=14]\n",
      "      +- FileScan parquet [X#68,Y#69,FID#70,DIVISION#71,LOCATION#72,PREC#73] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/LAPD_Police_Stations.parquet], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<X:double,Y:double,FID:int,DIVISION:string,LOCATION:string,PREC:int>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+-----+\n",
      "|year|  average_distance|    #|\n",
      "+----+------------------+-----+\n",
      "|2010|3.9757578208226914| 8162|\n",
      "|2011|2.4590852830727146| 7225|\n",
      "|2012|37.105294020349774| 6539|\n",
      "|2013| 2.459919591596096| 5851|\n",
      "|2014|10.659354948051488| 4559|\n",
      "|2015| 2.388986666887628| 6729|\n",
      "|2016|2.4268077758998485| 8094|\n",
      "|2017| 4.006458967994438| 7781|\n",
      "|2018|2.4123576588935918| 7414|\n",
      "|2019|2.4311257325392552| 7135|\n",
      "|2020| 8.300434266099332| 8496|\n",
      "|2021|  32.0668887686691|17410|\n",
      "|2022|2.3181733400905924|10139|\n",
      "|2023| 2.268385590446221| 8955|\n",
      "+----+------------------+-----+\n",
      "\n",
      "Method : BROADCAST | Time 113.53692102432251\n",
      "== Physical Plan ==\n",
      "CartesianProduct\n",
      ":- *(1) Project [DR_NO#0, gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS Date Rptd#80, gettimestamp(DATE OCC#2, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS DATE OCC#110, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#11, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      ":  +- *(1) ColumnarToRow\n",
      ":     +- FileScan parquet [DR_NO#0,Date Rptd#1,DATE OCC#2,TIME OCC#3,AREA #4,AREA NAME#5,Rpt Dist No#6,Part 1-2#7,Crm Cd#8,Crm Cd Desc#9,Mocodes#10,Vict Age#11,Vict Sex#12,Vict Descent#13,Premis Cd#14,Premis Desc#15,Weapon Used Cd#16,Weapon Desc#17,Status#18,Status Desc#19,Crm Cd 1#20,Crm Cd 2#21,Crm Cd 3#22,Crm Cd 4#23,... 4 more fields] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DR_NO:int,Date Rptd:string,DATE OCC:string,TIME OCC:int,AREA :int,AREA NAME:string,Rpt Dis...\n",
      "+- *(2) ColumnarToRow\n",
      "   +- FileScan parquet [X#68,Y#69,FID#70,DIVISION#71,LOCATION#72,PREC#73] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/LAPD_Police_Stations.parquet], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<X:double,Y:double,FID:int,DIVISION:string,LOCATION:string,PREC:int>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+-----+\n",
      "|year|  average_distance|    #|\n",
      "+----+------------------+-----+\n",
      "|2010|3.9757578208226914| 8162|\n",
      "|2011|2.4590852830727146| 7225|\n",
      "|2012|37.105294020349774| 6539|\n",
      "|2013| 2.459919591596096| 5851|\n",
      "|2014|10.659354948051488| 4559|\n",
      "|2015| 2.388986666887628| 6729|\n",
      "|2016|2.4268077758998485| 8094|\n",
      "|2017| 4.006458967994438| 7781|\n",
      "|2018|2.4123576588935918| 7414|\n",
      "|2019|2.4311257325392552| 7135|\n",
      "|2020| 8.300434266099332| 8496|\n",
      "|2021|  32.0668887686691|17410|\n",
      "|2022|2.3181733400905924|10139|\n",
      "|2023| 2.268385590446221| 8955|\n",
      "+----+------------------+-----+\n",
      "\n",
      "Method : SHUFFLE_REPLICATE_NL | Time 94.36919569969177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------                                        \n",
      "Exception occurred during processing of request from ('127.0.0.1', 44218)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/user/opt/spark/python/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/user/opt/spark/python/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "  File \"/home/user/opt/spark/python/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/user/opt/spark/python/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for method in ['BROADCAST','SHUFFLE_REPLICATE_NL']:\n",
    "    query_4_2a(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d14338-4bda-41cb-b43d-5731af568ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in ['BROADCAST','MERGE', 'SHUFFLE_HASH']:\n",
    "    query_4_2b(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08674079-e23f-46b1-b5b9-30c9c3f868a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
