{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56c50ab-5769-4e7d-946c-ec870888801c",
   "metadata": {},
   "source": [
    "#### Useful Links \n",
    "- Spark History Server : http://83.212.73.248:18080/\n",
    "- Hadoop YARN (scheduler) : http://83.212.73.248:8088/cluster\n",
    "- HDFS : http://83.212.73.248:9870/dfshealth.html#tab-overview\n",
    "\n",
    "#### Useful Commands : \n",
    "- Connect to okeanos-master (from local) : `$ ssh user@snf-40202.ok-kno.grnetcloud.net `\n",
    "    - Password : 'Rand0m'\n",
    "- Connect to okeanos-worker (from okeanos-master) : `$ ssh okeanos-worker`\n",
    "- Open Jupyter Notebook : `$ jupyter notebook --ip 83.212.73.248 --port 8888`\n",
    "\n",
    "#### Thinks to do :\n",
    "- Make the data Csv to Parquet\n",
    "- Make those columns the type we want\n",
    "- Write the Queries (!)\n",
    "- Benchmark and optimize them etc.\n",
    "- Balance the data onto HDFS across the two datanodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c667a612-a781-4680-bb05-0fdfe7aed047",
   "metadata": {},
   "source": [
    "### Full HDFS path is here : hdfs://okeanos-master:54310/csv_data/\n",
    "and contains :  \n",
    "     \n",
    "     1.  hdfs://okeanos-master:54310/csv_data/LAPD_Police_Stations.csv\n",
    "     2.  hdfs://okeanos-master:54310/csv_data/crime_data_2019.csv \n",
    "     3.  hdfs://okeanos-master:54310/csv_data/crime_data_2023.csv\n",
    "     4.  hdfs://okeanos-master:54310/csv_data/revgecoding.csv \n",
    "     5.  hdfs://okeanos-master:54310/csv_data/income/\n",
    "         1. LA_income_2015.csv\n",
    "         2. LA_income_2017.csv\n",
    "         3. LA_income_2019.csv\n",
    "         4. LA_income_2021.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a4e254-eda8-4782-a680-a9fc5c1d69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyspark Imports\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import col, regexp_replace\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "import geopy.distance\n",
    "import time \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbb858d-c65c-40f6-93c8-eae9504bbf51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/08 20:46:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/01/08 20:46:58 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "# initialize sparkSession, make the data from csv to parquet,\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"2 Executors\") \\\n",
    "    .config(\"spark.driver.cores\", \"1\") \\\n",
    "    .config(\"spark.driver.memory\", \"1g\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efaaacbe-53a0-4f5d-bf6f-f6eb6c42e3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# load data into memory, do the necessary joins etc. here\n",
    "crime_data = spark.read.parquet(\"hdfs://okeanos-master:54310/parquet/crime_data_*.parquet\")\n",
    "revge = spark.read.parquet(\"hdfs://okeanos-master:54310/parquet/revgecoding.parquet\")\n",
    "# only 2015 income data needed\n",
    "income = spark.read \\\n",
    "            .parquet(\"hdfs://okeanos-master:54310/parquet/income/LA_income_2015.parquet\")\n",
    "lapd_stations = spark.read.parquet(\"hdfs://okeanos-master:54310/parquet/LAPD_Police_Stations.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46505d2b-7003-4130-9d16-fd6e62490730",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_data = crime_data.withColumn(\"Date Rptd\", to_timestamp(\"Date Rptd\", 'MM/dd/yyyy hh:mm:ss a')) \\\n",
    "    .withColumn(\"DATE OCC\", to_timestamp(\"DATE OCC\", 'MM/dd/yyyy hh:mm:ss a')) \\\n",
    "    .withColumn(\"Vict Age\", col(\"Vict Age\").cast(\"int\")) \\\n",
    "    .withColumn(\"LAT\", col(\"LAT\").cast(\"double\")) \\\n",
    "    .withColumn(\"LON\", col(\"LON\").cast(\"double\")) \\\n",
    "    .withColumn(\"Premis_Desc\", col(\"Premis Desc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b0092c-d195-408a-9b21-05e93f33f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance on a sphere (as earth is not flat)\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    R = 6371\n",
    "    dLat = math.radians(lat2 - lat1)\n",
    "    dLon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dLat / 2) * math.sin(dLat / 2) + \\\n",
    "        math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dLon / 2) * math.sin(dLon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "haversine_udf = udf(haversine, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29fd9900-0641-46c3-8e49-b328101d00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_4_2a():\n",
    "    start_time = time.time()\n",
    "\n",
    "    crime_data_filtered = crime_data.withColumn('Weapon Used Cd', col('Weapon Used Cd').cast('int')) \\\n",
    "                                    .filter(col('Weapon Used Cd') < 200) \\\n",
    "                                    .withColumn('year', F.year('Date Rptd'))\n",
    "    crime_data_filtered.count()\n",
    "    combined_data = crime_data_filtered.hint('BROADCAST').crossJoin(broadcast(lapd_stations))\n",
    "\n",
    "    combined_data = combined_data.withColumn(\"closest_distance\", haversine_udf(col(\"LON\"), col(\"LAT\"), col(\"X\"), col(\"Y\")))\n",
    "    \n",
    "    windowSpec = Window.partitionBy(\"DR_NO\").orderBy(\"closest_distance\")\n",
    "    closest_stations = combined_data.withColumn(\"rank\", rank().over(windowSpec)).filter(col(\"rank\") == 1)\n",
    "    \n",
    "    final_data = closest_stations.select(col(\"DR_NO\"), col(\"DIVISION\").alias(\"closest_station\"), col(\"closest_distance\"))\n",
    "    \n",
    "    joined_with_stations = crime_data_filtered.join(final_data, \"DR_NO\")\n",
    "    \n",
    "    result = joined_with_stations.groupBy('year') \\\n",
    "        .agg((F.sum('closest_distance') / F.count('*')).alias('average_distance'),\n",
    "            F.count('*').alias('#')) \\\n",
    "       .orderBy(F.col('year'))\n",
    "\n",
    "    \n",
    "    result.show()\n",
    "    end_time = time.time()\n",
    "    print(f'Method : Broadcast | Time {end_time - start_time}')\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc5f5906-8fe1-4d31-9319-d5e8e714efc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_4_2a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54c80049-aaa8-4732-ac8f-7e3c354ecbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b)\n",
    "def query_4_2b(method = 'CONTINUE'):\n",
    "    start_time = time.time()\n",
    "\n",
    "    crime_data_filtered = crime_data.withColumn('Weapon Used Cd', col('Weapon Used Cd').cast('int')) \\\n",
    "                                  .filter(F.col('Weapon Used Cd').isNotNull()) \\\n",
    "                                  .withColumn('year', F.year('Date Rptd'))\n",
    "    \n",
    "    if method == 'BROADCAST':\n",
    "        combined_data = crime_data_filtered.hint(method).crossJoin(broadcast(lapd_stations))\n",
    "        combined_data.explain()\n",
    "        \n",
    "    elif method in ['MERGE', 'SHUFFLE_HASH', 'SHUFFLE_REPLICATE_NL']:\n",
    "        combined_data = crime_data.hint(method).crossJoin(lapd_stations)\n",
    "        combined_data.explain()\n",
    "        \n",
    "    elif method == 'CONTINUE':\n",
    "        combined_data = crime_data.crossJoin(lapd_stations)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    \n",
    "    combined_data = combined_data.withColumn(\"closest_distance\", haversine_udf(col(\"LON\"), col(\"LAT\"), col(\"X\"), col(\"Y\")))\n",
    "    \n",
    "    windowSpec = Window.partitionBy(\"DR_NO\").orderBy(\"closest_distance\")\n",
    "    closest_stations = combined_data.withColumn(\"rank\", rank().over(windowSpec)).filter(col(\"rank\") == 1)\n",
    "    \n",
    "    final_data = closest_stations.select(col(\"DR_NO\"), col(\"DIVISION\").alias(\"closest_station\"), col(\"closest_distance\"))\n",
    "    \n",
    "    joined_result = crime_data_filtered.join(final_data, \"DR_NO\")\n",
    "   # crime_data_join_stations = result.withColumn('Weapon Used Cd', col('Weapon Used Cd').cast('int')) \\\n",
    "   #                               .filter(F.col('Weapon Used Cd').isNotNull()) \\\n",
    "   #                                 .withColumn('year', F.year('Date Rptd'))\n",
    "    \n",
    "    result = joined_result.groupBy('AREA NAME') \\\n",
    "        .agg(\n",
    "            (F.sum('closest_distance') / F.count('*')).alias('average_distance'),\n",
    "            F.count('*').alias('#')\n",
    "        ) \\\n",
    "        .orderBy(F.col('#').desc()) \\\n",
    "        .withColumnRenamed('AREA NAME', 'division')\n",
    "    \n",
    "    result.show()\n",
    "    end_time = time.time()\n",
    "    print(f'Method : {method} | Time {end_time - start_time}')\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4db7b96f-9201-4927-97d6-497dfe6bbd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/08 20:47:37 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- BroadcastNestedLoopJoin BuildRight, Cross\n",
      "   :- Project [DR_NO#0, Date Rptd#80, DATE OCC#110, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#11, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 6 more fields]\n",
      "   :  +- Project [DR_NO#0, gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS Date Rptd#80, gettimestamp(DATE OCC#2, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS DATE OCC#110, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#11, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "   :     +- Filter isnotnull(Weapon Used Cd#16)\n",
      "   :        +- FileScan parquet [DR_NO#0,Date Rptd#1,DATE OCC#2,TIME OCC#3,AREA #4,AREA NAME#5,Rpt Dist No#6,Part 1-2#7,Crm Cd#8,Crm Cd Desc#9,Mocodes#10,Vict Age#11,Vict Sex#12,Vict Descent#13,Premis Cd#14,Premis Desc#15,Weapon Used Cd#16,Weapon Desc#17,Status#18,Status Desc#19,Crm Cd 1#20,Crm Cd 2#21,Crm Cd 3#22,Crm Cd 4#23,... 4 more fields] Batched: true, DataFilters: [isnotnull(Weapon Used Cd#16)], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [IsNotNull(`Weapon Used Cd`)], ReadSchema: struct<DR_NO:int,Date Rptd:string,DATE OCC:string,TIME OCC:int,AREA :int,AREA NAME:string,Rpt Dis...\n",
      "   +- BroadcastExchange IdentityBroadcastMode, [plan_id=20]\n",
      "      +- FileScan parquet [X#68,Y#69,FID#70,DIVISION#71,LOCATION#72,PREC#73] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/LAPD_Police_Stations.parquet], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<X:double,Y:double,FID:int,DIVISION:string,LOCATION:string,PREC:int>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-----+\n",
      "|   division|  average_distance|    #|\n",
      "+-----------+------------------+-----+\n",
      "|77th Street|  12.5671222967951|94853|\n",
      "|  Southeast| 25.60129873879751|87905|\n",
      "|  Southwest|   9.3291866625766|72814|\n",
      "|    Central|23.269811961478677|63606|\n",
      "|     Newton|13.433184721292792|61408|\n",
      "|    Olympic|36.348197450528986|60925|\n",
      "|    Rampart|19.629568008429306|55881|\n",
      "|  Hollywood|27.671748021149362|51255|\n",
      "|    Mission|34.800525588613944|48956|\n",
      "|    Pacific| 24.82546195967402|43019|\n",
      "|   Foothill|29.797575113580432|41625|\n",
      "| Hollenbeck| 19.52127635437576|41540|\n",
      "|N Hollywood|17.691483131562677|41151|\n",
      "|     Harbor| 13.98202798940977|40854|\n",
      "|    Topanga| 6.096105827278326|39337|\n",
      "|   Wilshire|15.736618712905988|37930|\n",
      "|  Northeast|12.367411075059353|37334|\n",
      "| Devonshire|23.046036251700613|36902|\n",
      "|   Van Nuys| 19.78805706517812|36264|\n",
      "|West Valley|14.718040243069364|34005|\n",
      "+-----------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Method : BROADCAST | Time 47.336594343185425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47.336594343185425"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_4_2b('BROADCAST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c24f896-c696-46d0-a667-c3d5559a3219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b)\n",
    "def query_4_2b_new(method = 'CONTINUE'):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if method == 'BROADCAST':\n",
    "        combined_data = crime_data.hint(method).crossJoin(broadcast(lapd_stations))\n",
    "        combined_data.explain()\n",
    "        \n",
    "    elif method in ['MERGE', 'SHUFFLE_HASH', 'SHUFFLE_REPLICATE_NL']:\n",
    "        combined_data = crime_data.hint(method).crossJoin(lapd_stations)\n",
    "        combined_data.explain()\n",
    "        \n",
    "    elif method == 'CONTINUE':\n",
    "        combined_data = crime_data.crossJoin(lapd_stations)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    \n",
    "    combined_data = combined_data.withColumn(\"closest_distance\", haversine_udf(col(\"LON\"), col(\"LAT\"), col(\"X\"), col(\"Y\")))\n",
    "    \n",
    "    windowSpec = Window.partitionBy(\"DR_NO\").orderBy(\"closest_distance\")\n",
    "    closest_stations = combined_data.withColumn(\"rank\", rank().over(windowSpec)).filter(col(\"rank\") == 1)\n",
    "    \n",
    "    final_data = closest_stations.select(col(\"DR_NO\"), col(\"DIVISION\").alias(\"closest_station\"), col(\"closest_distance\"))\n",
    "    \n",
    "    result = crime_data.join(final_data, \"DR_NO\")\n",
    "    crime_data_join_stations = result.withColumn('Weapon Used Cd', col('Weapon Used Cd').cast('int')) \\\n",
    "                                    .filter(F.col('Weapon Used Cd').isNotNull()) \\\n",
    "                                    .withColumn('year', F.year('Date Rptd'))\n",
    "    \n",
    "    result = crime_data_join_stations.groupBy('AREA NAME') \\\n",
    "        .agg(\n",
    "            (F.sum('closest_distance') / F.count('*')).alias('average_distance'),\n",
    "            F.count('*').alias('#')\n",
    "        ) \\\n",
    "        .orderBy(F.col('#').desc()) \\\n",
    "        .withColumnRenamed('AREA NAME', 'division')\n",
    "    \n",
    "    result.show()\n",
    "    end_time = time.time()\n",
    "    print(f'Method : {method} | Time {end_time - start_time}')\n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ad021d6-5926-4a3d-88e0-42ee21951b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- BroadcastNestedLoopJoin BuildRight, Cross\n",
      "   :- Project [DR_NO#0, gettimestamp(Date Rptd#1, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS Date Rptd#80, gettimestamp(DATE OCC#2, MM/dd/yyyy hh:mm:ss a, TimestampType, Some(Europe/Athens), false) AS DATE OCC#110, TIME OCC#3, AREA #4, AREA NAME#5, Rpt Dist No#6, Part 1-2#7, Crm Cd#8, Crm Cd Desc#9, Mocodes#10, Vict Age#11, Vict Sex#12, Vict Descent#13, Premis Cd#14, Premis Desc#15, Weapon Used Cd#16, Weapon Desc#17, Status#18, Status Desc#19, Crm Cd 1#20, Crm Cd 2#21, Crm Cd 3#22, Crm Cd 4#23, ... 5 more fields]\n",
      "   :  +- FileScan parquet [DR_NO#0,Date Rptd#1,DATE OCC#2,TIME OCC#3,AREA #4,AREA NAME#5,Rpt Dist No#6,Part 1-2#7,Crm Cd#8,Crm Cd Desc#9,Mocodes#10,Vict Age#11,Vict Sex#12,Vict Descent#13,Premis Cd#14,Premis Desc#15,Weapon Used Cd#16,Weapon Desc#17,Status#18,Status Desc#19,Crm Cd 1#20,Crm Cd 2#21,Crm Cd 3#22,Crm Cd 4#23,... 4 more fields] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(2 paths)[hdfs://okeanos-master:54310/parquet/crime_data_2019.parquet, hdfs://ok..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DR_NO:int,Date Rptd:string,DATE OCC:string,TIME OCC:int,AREA :int,AREA NAME:string,Rpt Dis...\n",
      "   +- BroadcastExchange IdentityBroadcastMode, [plan_id=535]\n",
      "      +- FileScan parquet [X#68,Y#69,FID#70,DIVISION#71,LOCATION#72,PREC#73] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[hdfs://okeanos-master:54310/parquet/LAPD_Police_Stations.parquet], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<X:double,Y:double,FID:int,DIVISION:string,LOCATION:string,PREC:int>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-----+\n",
      "|   division|  average_distance|    #|\n",
      "+-----------+------------------+-----+\n",
      "|77th Street|12.567122296795125|94853|\n",
      "|  Southeast| 25.60129873879752|87905|\n",
      "|  Southwest| 9.329186662576602|72814|\n",
      "|    Central|23.269811961478677|63606|\n",
      "|     Newton|13.433184721292793|61408|\n",
      "|    Olympic|   36.348197450529|60925|\n",
      "|    Rampart|19.629568008429306|55881|\n",
      "|  Hollywood|27.671748021149348|51255|\n",
      "|    Mission| 34.80052558861396|48956|\n",
      "|    Pacific| 24.82546195967405|43019|\n",
      "|   Foothill|29.797575113580425|41625|\n",
      "| Hollenbeck| 19.52127635437576|41540|\n",
      "|N Hollywood| 17.69148313156268|41151|\n",
      "|     Harbor|13.982027989409763|40854|\n",
      "|    Topanga| 6.096105827278324|39337|\n",
      "|   Wilshire|15.736618712905988|37930|\n",
      "|  Northeast|12.367411075059353|37334|\n",
      "| Devonshire|23.046036251700617|36902|\n",
      "|   Van Nuys|19.788057065178123|36264|\n",
      "|West Valley| 14.71804024306935|34005|\n",
      "+-----------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Method : BROADCAST | Time 97.07228922843933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97.07228922843933"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " query_4_2b_new('BROADCAST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6f556bc-5f45-4093-81ce-a5e060bc45af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "2993433\n",
      "109319\n",
      "72140\n",
      "2.5798370838165283\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lapd_stations_new = lapd_stations.withColumnRenamed('PREC','AREA')\n",
    "\n",
    "print(lapd_stations_new.count())\n",
    "\n",
    "print(crime_data.count())\n",
    "\n",
    "crime_data_filtered = crime_data.withColumn('Weapon Used Cd', col('Weapon Used Cd').cast('int')) \\\n",
    "                                  .filter(col('Weapon Used Cd') < 200) \n",
    "print(crime_data_filtered.count())\n",
    "\n",
    "#combined_data = crime_data_filtered.hint('BROADCAST').crossJoin(broadcast(lapd_stations))\n",
    "crime_data_join_stations = crime_data_filtered.withColumnRenamed('AREA ', 'AREA') \\\n",
    "                                    .join(broadcast(lapd_stations_new), 'AREA', 'inner')\n",
    "\n",
    "print(crime_data_join_stations.count())\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd7615f-9d92-4f56-8755-17298a2bfdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53fdc1d-0fa1-4f46-ac36-9605adb844bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.get(\"spark.executor.instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b586a4fc-878b-4370-91e1-36faca721379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crime_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0098ff2-3857-4604-8d16-5c26d003759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crime_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ad4d5-4e37-41a5-8833-7b3969368d31",
   "metadata": {},
   "source": [
    "#### Change Column Types \n",
    "Στην εκφωνηση λέει : Διατηρώντας τα αρχικά ονόματα στηλών \n",
    "\n",
    "εννοωντας οτι δεν μπορουμε να κανουμε το 'Date Rptd' -> 'Date_Rptd' ?\n",
    "- Date Rptd: date\n",
    "- DATE OCC: date\n",
    "- Vict Age: integer\n",
    "- LAT: double\n",
    "- LON: double\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b85974b-2551-4dda-859a-e86e3011dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for column type changing\n",
    "crime_data = crime_data.withColumn(\"Date Rptd\", to_timestamp(\"Date Rptd\", 'MM/dd/yyyy hh:mm:ss a')) \\\n",
    "    .withColumn(\"DATE OCC\", to_timestamp(\"DATE OCC\", 'MM/dd/yyyy hh:mm:ss a')) \\\n",
    "    .withColumn(\"Vict Age\", col(\"Vict Age\").cast(\"int\")) \\\n",
    "    .withColumn(\"LAT\", col(\"LAT\").cast(\"double\")) \\\n",
    "    .withColumn(\"LON\", col(\"LON\").cast(\"double\")) \\\n",
    "    .withColumn(\"Premis_Desc\", col(\"Premis Desc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c962e-49f3-4409-aa0e-3b113c973570",
   "metadata": {},
   "source": [
    "# 3rd Query :\n",
    "\n",
    "        find the 3 zip codes with min and max household income\n",
    "                    |\n",
    "                    |\n",
    "                    v\n",
    "        // filter(remove) victimless crimes\n",
    "                    |\n",
    "                    |\n",
    "                    v\n",
    "        select vict_desc, COUNT(*) as count\n",
    "        where year=2015\n",
    "        group by vict_desc\n",
    "        order by count DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8975de-3a0a-4735-a99c-92f24516b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code for 3rd query here\n",
    "def query_3(method = 'CONTINUE'):\n",
    "    start_time = time.time()\n",
    "    #crime_data_2015 = crime_data.filter(year(col('Date Rptd')) == 2015)\n",
    "    if method == 'BROADCAST':\n",
    "        crime_data_join_revge = crime_data.join(broadcast(revge), ['LAT', 'LON'], 'inner') \\\n",
    "            .withColumnRenamed('ZIPcode', 'Zip Code') \\\n",
    "            .withColumn(\"Zip Code\", col(\"Zip Code\").cast(\"int\")) \\\n",
    "            .filter((col('Vict Descent') != 'X') & (col('Vict Sex') != 'X'))\n",
    "        #crime_data_join_revge.explain()\n",
    "        \n",
    "    elif method in ['MERGE', 'SHUFFLE_HASH', 'SHUFFLE_REPLICATE_NL']:\n",
    "        crime_data_join_revge = crime_data.hint(method).join(revge, ['LAT', 'LON'], 'inner') \\\n",
    "            .withColumnRenamed('ZIPcode', 'Zip Code') \\\n",
    "            .withColumn(\"Zip Code\", col(\"Zip Code\").cast(\"int\")) \\\n",
    "            .filter((col('Vict Descent') != 'X') & (col('Vict Sex') != 'X'))\n",
    "        #crime_data_join_revge.explain()\n",
    "        \n",
    "    elif method == 'CONTINUE':\n",
    "        crime_data_join_revge = crime_data.join(revge, ['LAT', 'LON'], 'inner') \\\n",
    "            .withColumnRenamed('ZIPcode', 'Zip Code') \\\n",
    "            .withColumn(\"Zip Code\", col(\"Zip Code\").cast(\"int\")) \\\n",
    "            .filter((col('Vict Descent') != 'X') & (col('Vict Sex') != 'X'))\n",
    "        \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    #crime_data_join_revge = crime_data.join(revge, ['LAT', 'LON'], 'inner') \\\n",
    "    #    .withColumnRenamed('ZIPcode', 'Zip Code') \\\n",
    "    #    .withColumn(\"Zip Code\", col(\"Zip Code\").cast(\"int\")) \\\n",
    "    #    .filter((col('Vict Descent') != 'X') & (col('Vict Sex') != 'X'))\n",
    "    \n",
    "    crime_data_join_income = crime_data_join_revge.join(income, 'Zip Code', 'inner') \\\n",
    "                                .withColumn('Estimated Median Income', \n",
    "                                            regexp_replace(col('Estimated Median Income'), '[$,]', '')) \\\n",
    "                                .withColumn('Estimated Median Income', \n",
    "                                            col('Estimated Median Income') \\\n",
    "                                .cast('double'))\n",
    "    \n",
    "    max_income_zip_codes = crime_data_join_income.groupBy('Zip Code') \\\n",
    "                            .agg({'Estimated Median Income': 'max'}) \\\n",
    "                            .withColumnRenamed('max(Estimated Median Income)', 'MaxIncome') \\\n",
    "                            .orderBy(col('MaxIncome').desc()) \\\n",
    "                            .limit(3)\n",
    "    \n",
    "    min_income_zip_codes = crime_data_join_income.groupBy('Zip Code') \\\n",
    "                            .agg({'Estimated Median Income': 'min'}) \\\n",
    "                            .withColumnRenamed('min(Estimated Median Income)', 'MinIncome') \\\n",
    "                            .orderBy(col('MinIncome')) \\\n",
    "                            .limit(3)\n",
    "    \n",
    "    zip_codes = min_income_zip_codes.union(max_income_zip_codes)\n",
    "    \n",
    "    zip_codes_list = [row['Zip Code'] for row in zip_codes.collect()]\n",
    "    \n",
    "    result = crime_data_join_income \\\n",
    "                .filter(col('Zip Code').isin(zip_codes_list)) \\\n",
    "                .filter(year(col('Date Rptd')) == 2015) \\\n",
    "                .groupBy('Vict Descent') \\\n",
    "                .count() \\\n",
    "                .withColumnRenamed('count', '#') \\\n",
    "                .orderBy(col('#').desc())\n",
    "    \n",
    "    result.show()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    num_executors = spark.conf.get(\"spark.executor.instances\")\n",
    "    print(f'{num_executors} Executors')\n",
    "    \n",
    "    result.explain()\n",
    "    print(f'Method : {method} | Time {end_time - start_time}')\n",
    "    \n",
    "    return end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa9f130-baf2-4694-bdd5-217787fbba3d",
   "metadata": {},
   "source": [
    "# Query 3 on 2 Executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8260c478-9b3f-4e9e-8d71-39cde541e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7cc40a-866f-473d-a041-8777f3309771",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75001fad-9006-4cfc-a36b-2175c891b59a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
